{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62c18b4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c62c18b4",
    "outputId": "76fbe2fe-68b5-40ec-9297-b754f070b96f"
   },
   "outputs": [],
   "source": [
    "# pip install watermark lightgbm plotly cufflinks numpy pandas optuna torch pandas_ta gluonts pandas_datareader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "s2Q0FzF2JQIh",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "s2Q0FzF2JQIh",
    "outputId": "6b445e27-33e1-4bd5-899a-98f839863736"
   },
   "outputs": [],
   "source": [
    "# pip install -U git+https://github.com/unit8co/darts.git@master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395fd930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pytorch-forecasting==0.10.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129ffc3c",
   "metadata": {
    "id": "129ffc3c"
   },
   "outputs": [],
   "source": [
    "# 1. magic for inline plot\n",
    "# 2. magic to print version\n",
    "# 3. magic so that the notebook will reload external python modules\n",
    "# 4. magic to enable retina (high resolution) plots\n",
    "# https://gist.github.com/minrk/3301035\n",
    "%matplotlib inline\n",
    "%reload_ext watermark\n",
    "%config InlineBackend.figure_format='retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df345767",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "df345767",
    "outputId": "c1dfac25-33b8-48e7-e9bf-34341033439e"
   },
   "outputs": [],
   "source": [
    "%watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364f8efb",
   "metadata": {
    "id": "364f8efb"
   },
   "outputs": [],
   "source": [
    "# conda install -c conda-forge 'u8darts'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e31e795",
   "metadata": {
    "id": "8e31e795"
   },
   "source": [
    "### Library imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b05fbe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "81b05fbe",
    "outputId": "b6141785-035e-47ba-c0e2-150468a163e2"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import darts\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# pip install matplotlib==3.1.2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import plotly.offline\n",
    "import cufflinks as cf\n",
    "cf.go_offline()\n",
    "cf.set_config_file(offline=False, world_readable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae337963",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import EarlyStopping, LearningRateMonitor\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from pytorch_forecasting import Baseline, TemporalFusionTransformer, TimeSeriesDataSet\n",
    "from pytorch_forecasting.data import GroupNormalizer\n",
    "from pytorch_forecasting.metrics import SMAPE, PoissonLoss, QuantileLoss\n",
    "from pytorch_forecasting.models.temporal_fusion_transformer.tuning import optimize_hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f755d351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -U \"u8darts[torch]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c94ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_forecasting\n",
    "pytorch_forecasting.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e94c945",
   "metadata": {
    "id": "2e94c945"
   },
   "source": [
    "### Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78e90ff",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a78e90ff",
    "outputId": "62d47171-1ec1-47e5-9d65-f98078071113"
   },
   "outputs": [],
   "source": [
    "pl.seed_everything(42)\n",
    "\n",
    "import random\n",
    "random.seed(0)\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "\n",
    "import torch\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424cdf80",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "id": "424cdf80",
    "outputId": "9548de8a-12cd-46da-f3f6-bdefbfadb8d0"
   },
   "outputs": [],
   "source": [
    "df_m6 = pd.read_csv(\"M6_Universe.csv\", index_col=0)\n",
    "df_m6.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a499885a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks = df_m6[df_m6[\"class\"]==\"Stock\"][\"symbol\"].values\n",
    "etfs = df_m6[df_m6[\"class\"]==\"ETF\"][\"symbol\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216285c9",
   "metadata": {
    "id": "216285c9"
   },
   "outputs": [],
   "source": [
    "SAMPLE_SIZE = 100\n",
    "FORECAST_HORIZON = 20 #days\n",
    "PERIODS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceaeecdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import yfinance as yf\n",
    "# import warnings\n",
    "\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "# pd.options.display.float_format = '{:.4%}'.format\n",
    "\n",
    "# # Date range\n",
    "# start = '2020-01-01'\n",
    "# end = '2022-04-30'\n",
    "\n",
    "# # Tickers of assets\n",
    "# df_m6 = pd.read_csv(\"M6_Universe.csv\", index_col=0)\n",
    "# df_m6.head(5)\n",
    "# assets = list(df_m6[\"symbol\"].values)\n",
    "\n",
    "# # Downloading data\n",
    "# data = yf.download(assets, start = start, end = end)\n",
    "# data = data.loc[:,('Adj Close', slice(None))]\n",
    "# data.columns = assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a73d1cc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86,
     "referenced_widgets": [
      "b7d303b547924163acb02c690cfac7c7",
      "81ff9d16b3624054984a94baf2998fad",
      "3fb3e0fe97e54db99c0532a66911bc84",
      "1add1e8945964e189c63557224b740fc",
      "96bdac24271c490caeafed06be53e2fd",
      "f3fc925008d64eb3af346326f11737cf",
      "073685966c774b01953c0343bef00251",
      "c0774078b6954b58afa08a657c648e37",
      "4c3eb9334739464aaa3ef7b87c6369ac",
      "ec425fa026f84d359130572ee193b14f",
      "742a3ef153ee4c1fa4a7ced4c899c0e0"
     ]
    },
    "id": "7a73d1cc",
    "outputId": "da93f97c-de29-45a8-e6db-22020c88a06a"
   },
   "outputs": [],
   "source": [
    "from src.io import get_m6_tickers_data\n",
    "tickers_data = get_m6_tickers_data(tickers=df_m6[\"symbol\"].to_list(), \n",
    "                                   from_date=pd.to_datetime(\"2018-01-01\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ece5a56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b7ef24",
   "metadata": {
    "id": "07b7ef24"
   },
   "outputs": [],
   "source": [
    "from src.ticket_features import calculate_pct_returns, calculate_log_returns, calculate_cum_log_returns, calculate_cum_pct_returns\n",
    "\n",
    "df = pd.DataFrame.from_dict({k: v['Adj Close'] for k, v in tickers_data.items()})\n",
    "df_cum_log_returns = df.apply(calculate_cum_log_returns, periods=PERIODS, axis=0)\n",
    "df_cum_prt_returns = df.apply(calculate_cum_pct_returns, periods=PERIODS, axis=0)\n",
    "df_log_returns = df.apply(calculate_log_returns, periods=PERIODS, axis=0)\n",
    "df_prc_returns = df.apply(calculate_pct_returns, periods=PERIODS, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e02cc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_etfs_prc_returns = df[etfs].copy()\n",
    "# df_stock_prc_returns = df[stocks].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895b84c0",
   "metadata": {
    "id": "895b84c0"
   },
   "source": [
    "### Reindex dates and fill in with previous values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c4768f",
   "metadata": {
    "id": "c7c4768f"
   },
   "outputs": [],
   "source": [
    "from gluonts.time_feature.holiday import (\n",
    "    squared_exponential_kernel,\n",
    "    SpecialDateFeatureSet,\n",
    "    NEW_YEARS_DAY,\n",
    "    MARTIN_LUTHER_KING_DAY,\n",
    "    PRESIDENTS_DAY,\n",
    "    GOOD_FRIDAY,\n",
    "    MEMORIAL_DAY,\n",
    "    INDEPENDENCE_DAY,\n",
    "    LABOR_DAY,\n",
    "    THANKSGIVING,\n",
    "    CHRISTMAS_DAY,\n",
    "    SUPERBOWL,\n",
    "    CHRISTMAS_EVE,\n",
    "    EASTER_SUNDAY,\n",
    "    EASTER_MONDAY,\n",
    "    MOTHERS_DAY,\n",
    "    COLUMBUS_DAY,\n",
    "    NEW_YEARS_EVE,\n",
    "    BLACK_FRIDAY,\n",
    "    CYBER_MONDAY\n",
    ")\n",
    "\n",
    "# Example use for using a squared exponential kernel:\n",
    "kernel = squared_exponential_kernel(alpha=1.0)\n",
    "sfs = SpecialDateFeatureSet([NEW_YEARS_DAY,\n",
    "                             MARTIN_LUTHER_KING_DAY,\n",
    "                             PRESIDENTS_DAY,\n",
    "                             GOOD_FRIDAY,\n",
    "                             MEMORIAL_DAY,\n",
    "                             INDEPENDENCE_DAY,\n",
    "                             LABOR_DAY,\n",
    "                             THANKSGIVING,\n",
    "                             CHRISTMAS_DAY],\n",
    "                            kernel)\n",
    "\n",
    "sfs2 = SpecialDateFeatureSet([SUPERBOWL,\n",
    "                              CHRISTMAS_EVE,\n",
    "                              EASTER_SUNDAY,\n",
    "                              EASTER_MONDAY,\n",
    "                              MOTHERS_DAY,\n",
    "                              COLUMBUS_DAY,\n",
    "                              NEW_YEARS_EVE,\n",
    "                              BLACK_FRIDAY,\n",
    "                              CYBER_MONDAY],\n",
    "                            kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17b8aed",
   "metadata": {
    "id": "d17b8aed"
   },
   "outputs": [],
   "source": [
    "from src.strategy import CustomStrategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87ffa35",
   "metadata": {
    "id": "f87ffa35"
   },
   "outputs": [],
   "source": [
    "# Make a pipeline with the steps\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion, make_pipeline\n",
    "from transformers import DateTimeTransformer, periodic_spline_transformer\n",
    "from reduce_memory import ReduceMemoryTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "date_time_transforms = make_pipeline(\n",
    "    DateTimeTransformer()\n",
    ")\n",
    "\n",
    "memory_transforms = make_pipeline(\n",
    "    ReduceMemoryTransformer()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ad2232",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966c7f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stock_returns_quantiles = reindex_weekdays(df.copy())\n",
    "df_stock_returns_quantiles = (df_stock_returns_quantiles\n",
    "                              .apply(calculate_pct_returns, periods=PERIODS, axis=0)\n",
    "                              .apply(lambda x: x + np.random.normal(0, 1e-12, size=(100)), axis=1)\n",
    "                              .dropna()\n",
    "                              .rank(1, ascending=True, method='min') // (20.+1e-12) + 1).clip(upper=5).astype(int)\n",
    "df_stock_returns_quantiles -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578a2ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_stock_returns_quantiles[\"2022-04-29\":\"2022-04-29\"].T.reset_index().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d086e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_etf_returns_quantiles = reindex_weekdays(df[etfs]).copy()\n",
    "# df_etf_returns_quantiles = (df_etf_returns_quantiles\n",
    "#                               .apply(calculate_pct_returns, periods=PERIODS, axis=0)\n",
    "#                               .apply(lambda x: x + np.random.normal(0, .000001, size=(50)), axis=1)\n",
    "#                               .dropna()\n",
    "#                               .rank(1, ascending=True, method='min') // 10.00000001 + 1).clip(upper=5).astype(int)\n",
    "# df_etf_returns_quantiles -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2eb6583",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a2eb6583",
    "outputId": "40c94018-fa20-4b6d-f386-8e766c73081f"
   },
   "outputs": [],
   "source": [
    "# covariates = get_datetime_covariates(start_index, end_index, memory_transforms, date_time_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36d157b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d36d157b",
    "outputId": "07fb0ac2-5688-4a96-ff8f-ad762a51e473"
   },
   "outputs": [],
   "source": [
    "from src.ticket_features import upper_shadow, lower_shadow, upper_shadow_percent, lower_shadow_percent\n",
    "\n",
    "tickers_data_enriched = {}\n",
    "\n",
    "for k, v in tickers_data.items():\n",
    "    df = v.copy()\n",
    "    df = reindex_weekdays(df)\n",
    "    df.ta.strategy(CustomStrategy)\n",
    "    df.ta.percent_return(cumulative=False, append=True)\n",
    "    df.ta.percent_return(cumulative=False, length=PERIODS, append=True)\n",
    "    #     df = (df\n",
    "    #         .reindex(pd.date_range(start=df.index[0], end=end_index, freq='D'))\n",
    "    #         .fillna(method='ffill')\n",
    "    #         .fillna(method='bfill')\n",
    "    #     )\n",
    "    df[f\"cum_log_returns_{PERIODS}\"] = df[[\"Adj Close\"]].apply(calculate_cum_log_returns, periods=PERIODS, axis=0).values\n",
    "    df[f\"log_returns_{PERIODS}\"] = df[[\"Adj Close\"]].apply(calculate_log_returns, periods=PERIODS, axis=0).values\n",
    "    df['high2low'] = df['High'] / df['Low']\n",
    "    df['var'] = df['Adj Close'].var()\n",
    "    df['target_var'] = df[f'PCTRET_{PERIODS}'].var()\n",
    "    df['upper_shadow'] = upper_shadow(df)\n",
    "    df['lower_shadow'] = lower_shadow(df)\n",
    "    df['upper_shadow_percent'] = upper_shadow_percent(df)\n",
    "    df['lower_shadow_percent'] = lower_shadow_percent(df)    \n",
    "    \n",
    "    df[\"GICS_sector/ETF_type\"] = df_m6[df_m6[\"symbol\"]==k][\"GICS_sector/ETF_type\"].values[0]\n",
    "    df[\"GICS_industry/ETF_subtype\"] = df_m6[df_m6[\"symbol\"]==k][\"GICS_industry/ETF_subtype\"].values[0]\n",
    "    df[\"group\"] = k\n",
    "    df[\"ticket\"] = \"stock\" if k in stocks else \"etf\"\n",
    "    #df[\"month\"] = df.index.month #.astype(str).astype(\"category\")  # categories have be strings\n",
    "    df[\"day_of_week\"] = df.index.day_of_week #.astype(str).astype(\"category\")  # categories have be strings\n",
    "    df[\"log_volume\"] = np.log(df[\"Volume\"] + 1e-8)\n",
    "    df = memory_transforms.fit_transform(df)\n",
    "    #     scaler = MinMaxScaler() #StandardScaler()\n",
    "    #     df_scaled = pd.DataFrame(data=scaler.fit_transform(df), \n",
    "    #                              index=df.index,\n",
    "    #                              columns=df.columns)\n",
    "    #     df_scaled.dropna(inplace=True)\n",
    "    #     tickers_data_enriched[k] = df_scaled\n",
    "    tickers_data_enriched[k] = df#[df_stock_returns_quantiles.index[0]:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b85001",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.concat([pd.concat([df_stock_returns_quantiles[[k]].rename(columns={k: \"target\"}),\n",
    "                              #pd.concat([df_stock_returns_quantiles[[k]].shift(i).rename(columns={k: f\"target_shift_{i}\"}) for i in range(1, FORECAST_HORIZON+1)], axis=1).fillna(method=\"bfill\"),\n",
    "                              tickers_data_enriched[k], \n",
    "                             #covariates\n",
    "                            ], axis=1).dropna().reset_index(drop=True).reset_index() \n",
    "                  for k in tickers_data_enriched.keys()])\n",
    "\n",
    "# data2 = pd.concat([pd.concat([df_etf_returns_quantiles[[k]].rename(columns={k: \"target\"}), \n",
    "#                               #pd.concat([df_etf_returns_quantiles[[k]].shift(i).rename(columns={k: f\"target_shift_{i}\"}) for i in range(1, FORECAST_HORIZON+1)], axis=1).fillna(method=\"bfill\"),\n",
    "#                               tickers_data_enriched[k], \n",
    "#                              #covariates\n",
    "#                             ], axis=1).dropna().reset_index(drop=True).reset_index() \n",
    "#                   for k in etfs])\n",
    "\n",
    "# data = pd.concat([data1, data2]).reset_index(drop=True).rename(columns={\"index\":\"time_index\"})\n",
    "data = data1.reset_index(drop=True).rename(columns={\"index\":\"time_index\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a91cab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = data.columns[data.isna().any()]\n",
    "# data.loc[:, columns] = data.loc[:, columns].astype(str).fillna(method='bfill').astype(float)\n",
    "# data.drop(columns, axis=1)\n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43f0220",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_varying_known_categoricals = ['day_of_week'] # 'month', \n",
    "static_columns = [\"group\", \"ticket\", 'GICS_sector/ETF_type','GICS_industry/ETF_subtype']\n",
    "time_var_reals = list(tickers_data_enriched[\"ABBV\"].columns[~tickers_data_enriched[\"ABBV\"].columns.isin(static_columns+time_varying_known_categoricals)]) \\\n",
    "                 #+ list(covariates.reset_index().columns)\n",
    "data.columns = [d.replace('.','_') for d in data.columns]\n",
    "time_var_reals = [d.replace('.','_') for d in time_var_reals]\n",
    "time_var_reals = [i for i in time_var_reals if i!=\"time_index\"]\n",
    "\n",
    "data = memory_transforms.fit_transform(data)\n",
    "data['target'] = data['target'].astype(int)\n",
    "# data['month'] = data['month'].astype(str)\n",
    "data['day_of_week'] = data['day_of_week'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93aca48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['time_index'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5448572a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "from pytorch_forecasting.data.encoders import EncoderNormalizer, TorchNormalizer\n",
    "\n",
    "max_prediction_length = FORECAST_HORIZON\n",
    "max_encoder_length = PERIODS\n",
    "training_cutoff = data['time_index'].max() - 4*FORECAST_HORIZON\n",
    "# training_cutoff = data['time_index'].min() + 5*FORECAST_HORIZON\n",
    "\n",
    "training = TimeSeriesDataSet(\n",
    "    data[lambda x: x['time_index'] <= training_cutoff],\n",
    "    time_idx=\"time_index\",\n",
    "    target=\"target\",\n",
    "    group_ids=[\"group\"],\n",
    "    min_encoder_length=max_encoder_length // 2,  # keep encoder length long (as it is in the validation set)\n",
    "    max_encoder_length=max_encoder_length,\n",
    "    min_prediction_length=1,\n",
    "    max_prediction_length=max_prediction_length,\n",
    "    static_categoricals=static_columns,\n",
    "    static_reals=[], #\"avg_population_2017\", \"avg_yearly_household_income_2017\"],\n",
    "    time_varying_known_categoricals=time_varying_known_categoricals,#\"special_days\", \"month\"],\n",
    "    variable_groups={}, # \"special_days\": special_days},  # group of categorical variables can be treated as one variable\n",
    "    time_varying_known_reals=[\"time_index\"],\n",
    "    time_varying_unknown_categoricals=[],\n",
    "    time_varying_unknown_reals=[\"target\"]+time_var_reals,\n",
    "    # lags={\"target\": [i for i in range(1,max_prediction_length+1)]},\n",
    "    #target_normalizer=NaNLabelEncoder(),\n",
    "    #GroupNormalizer(\n",
    "    #   groups=group_columns, transformation=(F.one_hot, torch.argmax)\n",
    "    #),  # use softplus and normalize by group\n",
    "#     target_normalizer = TorchNormalizer(transformation=(F.one_hot, torch.argmax)), \n",
    "    add_relative_time_idx=True,\n",
    "    add_target_scales=False,\n",
    "    add_encoder_length=False,\n",
    "    #allow_missing_timesteps=True,\n",
    "    #add_nan=True\n",
    ")\n",
    "\n",
    "# create validation set (predict=True) which means to predict the last max_prediction_length points in time\n",
    "# for each series\n",
    "validation = TimeSeriesDataSet.from_dataset(training, data, predict=True, stop_randomization=True)\n",
    "\n",
    "# create dataloaders for model\n",
    "batch_size = 128  # set this between 32 to 128\n",
    "train_dataloader = training.to_dataloader(train=True, batch_size=batch_size, num_workers=0)\n",
    "val_dataloader = validation.to_dataloader(train=False, batch_size=batch_size * 10, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189f25c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_forecasting.metrics import MultiHorizonMetric\n",
    "from typing import Dict\n",
    "# from metrics import torch_rps\n",
    "\n",
    "def rps_loss(y_pred, target):\n",
    "        probs = F.softmax(y_pred)\n",
    "        outcome = F.one_hot(target, num_classes=5)\n",
    "        loss = torch.mean(((torch.cumsum(probs, dim=-1) - torch.cumsum(outcome, dim=-1))**2).double(), dim=-1, keepdim=True)\n",
    "        return loss\n",
    "\n",
    "class RPS(MultiHorizonMetric):\n",
    "    \n",
    "    def loss(self, y_pred, target):\n",
    "        y_pred = F.softmax(y_pred, dim=-1)\n",
    "        target = F.one_hot(target, num_classes=5)\n",
    "        #loss = torch_rps(y_pred, target)\n",
    "        loss = torch.mean(((torch.cumsum(y_pred, dim=-1) - torch.cumsum(target, dim=-1))**2).double(), dim=-1, keepdim=True)\n",
    "        return loss\n",
    "\n",
    "    def to_quantiles(self, out: Dict[str, torch.Tensor], quantiles=None):\n",
    "        return out\n",
    "    \n",
    "    def to_prediction(self, y_pred: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Convert network prediction into a point prediction.\n",
    "\n",
    "        Args:\n",
    "            y_pred: prediction output of network\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: point prediction\n",
    "        \"\"\"\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba312c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_forecasting import Baseline, DeepAR, TimeSeriesDataSet\n",
    "# from metrics import RPS, torch_rps\n",
    "# configure network and trainer\n",
    "early_stop_callback = EarlyStopping(monitor=\"val_loss\", min_delta=1e-4, patience=10, verbose=False, mode=\"min\")\n",
    "lr_logger = LearningRateMonitor()  # log the learning rate\n",
    "logger = TensorBoardLogger(\"lightning_logs\")  # logging results to a tensorboard\n",
    "\n",
    "# configure network and trainer\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=10,\n",
    "    gpus=0,\n",
    "    # clipping gradients is a hyperparameter and important to prevent divergance\n",
    "    # of the gradient for recurrent neural networks\n",
    "    gradient_clip_val=0.1,\n",
    "    #limit_train_batches=30,  # coment in for training, running valiation every 30 batches\n",
    "    # fast_dev_run=True,  # comment in to check that networkor dataset has no serious bugs\n",
    "    callbacks=[early_stop_callback], #lr_logger, \n",
    "    #logger=logger,\n",
    ")\n",
    "\n",
    "net = TemporalFusionTransformer.from_dataset(\n",
    "    training,\n",
    "    # not meaningful for finding the learning rate but otherwise very important\n",
    "    learning_rate=0.01,\n",
    "    hidden_size=16,  # most important hyperparameter apart from learning rate\n",
    "    # number of attention heads. Set to up to 4 for large datasets\n",
    "    attention_head_size=1,\n",
    "    dropout=0.5,  # between 0.1 and 0.3 are good values\n",
    "    hidden_continuous_size=8,  # set to <= hidden_size\n",
    "    output_size=5, # 5 categories by default\n",
    "    loss=RPS(),\n",
    "    # reduce learning rate if no improvement in validation loss after x epochs\n",
    "    reduce_on_plateau_patience=4,\n",
    "    #log_interval=10,  # uncomment for learning rate finder and otherwise, e.g. to 10 for logging every 10 batches\n",
    "    logging_metrics=torch.nn.ModuleList([RPS()])\n",
    ")\n",
    "print(f\"Number of parameters in network: {net.size()/1e3:.1f}k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85039c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # find optimal learning rate\n",
    "# res = trainer.tuner.lr_find(\n",
    "#     net,\n",
    "#     train_dataloaders=train_dataloader,\n",
    "#     val_dataloaders=val_dataloader,\n",
    "#     max_lr=10.0,\n",
    "#     min_lr=1e-6,\n",
    "# )\n",
    "\n",
    "# print(f\"suggested learning rate: {res.suggestion()}\")\n",
    "# fig = res.plot(show=True, suggest=True)\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50867e1d",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e700ec52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rps_loss(y_pred, target):\n",
    "        probs = F.softmax(y_pred)\n",
    "        outcome = F.one_hot(target, num_classes=5)\n",
    "        loss = torch.mean(((torch.cumsum(probs, dim=-1) - torch.cumsum(outcome, dim=-1))**2).double(), dim=-1, keepdim=True)\n",
    "        return loss\n",
    "# calculate baseline mean absolute error, i.e. predict next value as the last available value from the history\n",
    "actuals = torch.cat([y for x, (y, weight) in iter(val_dataloader)])\n",
    "baseline_predictions = Baseline().predict(val_dataloader)\n",
    "rps_loss(baseline_predictions, actuals).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b3aee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit network\n",
    "trainer.fit(\n",
    "    net,\n",
    "    train_dataloaders=train_dataloader,\n",
    "    val_dataloaders=val_dataloader,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5b6528",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6659f0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# from pytorch_forecasting.models.temporal_fusion_transformer.tuning import optimize_hyperparameters\n",
    "\n",
    "# # create study\n",
    "# study = optimize_hyperparameters(\n",
    "#     train_dataloader,\n",
    "#     val_dataloader,\n",
    "#     model_path=\"optuna_test\",\n",
    "#     n_trials=100,\n",
    "#     max_epochs=10,\n",
    "#     gradient_clip_val_range=(0.01, 1.0),\n",
    "#     hidden_size_range=(8, 128),\n",
    "#     hidden_continuous_size_range=(8, 128),\n",
    "#     attention_head_size_range=(1, 4),\n",
    "#     learning_rate_range=(0.001, 0.1),\n",
    "#     dropout_range=(0.1, 0.3),\n",
    "#     trainer_kwargs=dict(limit_train_batches=30),\n",
    "#     reduce_on_plateau_patience=4,\n",
    "#     use_learning_rate_finder=False,  # use Optuna to find ideal learning rate or use in-built learning rate finder\n",
    "# )\n",
    "\n",
    "# # save study results - also we can resume tuning at a later point in time\n",
    "# with open(\"test_study.pkl\", \"wb\") as fout:\n",
    "#     pickle.dump(study, fout)\n",
    "\n",
    "# # show best hyperparameters\n",
    "# print(study.best_trial.params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22540121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the best model according to the validation loss\n",
    "# (given that we use early stopping, this is not necessarily the last epoch)\n",
    "best_model_path = trainer.checkpoint_callback.best_model_path\n",
    "best_tft = TemporalFusionTransformer.load_from_checkpoint(best_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5974cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcualte mean absolute error on validation set\n",
    "actuals = torch.cat([y[0] for x, y in iter(val_dataloader)])\n",
    "x, y = next(iter(val_dataloader))\n",
    "predictions = best_tft(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333d236b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw predictions are a dictionary from which all kind of information including quantiles can be extracted\n",
    "raw_predictions, x = best_tft.predict(val_dataloader, mode=\"raw\", return_x=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc72fee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpretation = best_tft.interpret_output(raw_predictions, reduction=\"sum\")\n",
    "best_tft.plot_interpretation(interpretation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37dab512",
   "metadata": {},
   "outputs": [],
   "source": [
    "#F.softmax(raw_predictions['prediction'], dim=-1)#.argmax(dim=-1)\n",
    "loss = RPS().loss(raw_predictions['prediction'][:,:,:], x['decoder_target'][:,:]).detach().numpy().squeeze()\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16efe95",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_predictions['prediction'][:,:,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0af4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(loss, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4f98d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import plotly.express as px\n",
    "\n",
    "fig = px.imshow(loss.T, \n",
    "                color_continuous_scale=\"Cividis\", \n",
    "                origin='lower', \n",
    "                title=f\"Mean loss {np.mean(loss)}\"\n",
    "               )\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb92cc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa48172d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_tft.plot_prediction(x, raw_predictions, idx=2, add_loss_to_title=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0eb825c",
   "metadata": {},
   "source": [
    "## Submission "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb51af7",
   "metadata": {},
   "source": [
    "### Predict on new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb48eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select last 20 days from data (max_encoder_length is 20)\n",
    "new_enc_data = []\n",
    "for ticket in [*stocks, *etfs]:\n",
    "    ticket_data = data[data.group==ticket]\n",
    "    encoder_data = ticket_data[lambda x: x.time_index > x.time_index.max() - max_encoder_length]\n",
    "    new_enc_data.append(encoder_data)\n",
    "encoder_data = pd.concat(new_enc_data)\n",
    "\n",
    "# select last known data point and create decoder data from it by repeating it and incrementing the month\n",
    "# in a real world dataset, we should not just forward fill the covariates but specify them to account\n",
    "# for changes in special days and prices (which you absolutely should do but we are too lazy here)\n",
    "new_dec_data = []\n",
    "for ticket in [*stocks, *etfs]:\n",
    "    ticket_data = data[data.group==ticket]\n",
    "    last_ticket_data = ticket_data[lambda x: x.time_index == x.time_index.max()]\n",
    "    decoder_data = pd.concat(\n",
    "        [last_ticket_data.assign(time_index=lambda x: x.time_index + i) for i in range(1, max_prediction_length + 1)],\n",
    "        ignore_index=True,\n",
    "    )\n",
    "    new_dec_data.append(decoder_data)\n",
    "decoder_data = pd.concat(new_dec_data)\n",
    "\n",
    "#decoder_data[\"month\"] = ((encoder_data[\"month\"]).astype(int) + 1).astype(str).values\n",
    "decoder_data[\"day_of_week\"] = encoder_data[\"day_of_week\"].values\n",
    "\n",
    "# combine encoder and decoder data\n",
    "new_prediction_data = pd.concat([encoder_data, decoder_data], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48d7ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw predictions are a dictionary from which all kind of information including quantiles can be extracted\n",
    "new_raw_predictions, new_x = best_tft.predict(new_prediction_data, mode=\"raw\", return_x=True)\n",
    "\n",
    "for idx in range(10):  # plot 10 examples\n",
    "    best_tft.plot_prediction(new_x, new_raw_predictions, idx=idx, \n",
    "                             show_future_observed=False, add_loss_to_title=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a049f553",
   "metadata": {},
   "outputs": [],
   "source": [
    "def submit_forecasts(raw_predictions, decimals=5):\n",
    "    df_submission = pd.read_csv(\"template.csv\", index_col=0)\n",
    "    df_submission.iloc[:,:-1] = F.softmax(raw_predictions['prediction'], dim=-1).numpy()[:,-1,:]\n",
    "    df_submission.iloc[:,:-1] = df_submission.iloc[:,:-1].round(decimals)\n",
    "    df_submission.iloc[:, 0] += (1 - df_submission.iloc[:,:-1].sum(1).round(decimals))\n",
    "    df_submission.round(decimals).to_csv(\"./results/submission_sub4.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7a272a",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_forecasts(new_raw_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bb2dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (pd.read_csv(\"./results/submission_sub4.csv\").iloc[:,1:6] + pd.read_csv(\"./template.csv\").iloc[:,1:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ca799f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./results/submission_sub4.csv\").iloc[:,1:6] \n",
    "df = df/2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62bce581",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"./results/submission_sub4.csv\")\n",
    "df1.iloc[:,1:6] = df\n",
    "df1.to_csv(\"./results/submission_sub4.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5537458",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = RPS().loss(raw_predictions['prediction'], x['decoder_target']).detach().numpy().squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0a5999",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns; sns.set_theme()\n",
    "ax = sns.heatmap(loss.T[:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a4c198",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8bb647",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = px.imshow(loss.T, \n",
    "                color_continuous_scale=\"Cividis\", \n",
    "                origin='lower', \n",
    "                title=\"Missing values\"\n",
    "               )\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7269cc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68957049",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['Rank 1','Rank 2','Rank 3','Rank 4','Rank 5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcf56bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc815af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84acea12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be2dc0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e926673",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "dc63743e"
   ],
   "name": "Darts forecasts.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "073685966c774b01953c0343bef00251": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "08db2b9a48c542adbe8cc7e06bb31871": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c6d702c50e9840e69a9e75caf2bdb4b0",
      "max": 100,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4d8362c0442e446abcd1f36928c2b8e9",
      "value": 100
     }
    },
    "1add1e8945964e189c63557224b740fc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4c3eb9334739464aaa3ef7b87c6369ac",
      "max": 100,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c0774078b6954b58afa08a657c648e37",
      "value": 100
     }
    },
    "3fb3e0fe97e54db99c0532a66911bc84": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_073685966c774b01953c0343bef00251",
      "placeholder": "​",
      "style": "IPY_MODEL_f3fc925008d64eb3af346326f11737cf",
      "value": "100%"
     }
    },
    "4c2e235e63d64196964deec526f3784c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4c3eb9334739464aaa3ef7b87c6369ac": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4d8362c0442e446abcd1f36928c2b8e9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "53173af3160b4b758ed2c33d3b554008": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_75bdf511cc3242eaae63569a7d40f4b6",
      "placeholder": "​",
      "style": "IPY_MODEL_e6f3d7eb344d40a4b9fd97a3617a94f9",
      "value": " 100/100 [00:05&lt;00:00, 20.52it/s]"
     }
    },
    "5b705b8c225d4d76b46b50c9f510a40e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c575ac2e09424c3f8fc76c924b1314f4",
       "IPY_MODEL_08db2b9a48c542adbe8cc7e06bb31871",
       "IPY_MODEL_53173af3160b4b758ed2c33d3b554008"
      ],
      "layout": "IPY_MODEL_86f69349b4b94dc68923fbcd72d1a2b1"
     }
    },
    "742a3ef153ee4c1fa4a7ced4c899c0e0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "75bdf511cc3242eaae63569a7d40f4b6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "81ff9d16b3624054984a94baf2998fad": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "86f69349b4b94dc68923fbcd72d1a2b1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "96bdac24271c490caeafed06be53e2fd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_742a3ef153ee4c1fa4a7ced4c899c0e0",
      "placeholder": "​",
      "style": "IPY_MODEL_ec425fa026f84d359130572ee193b14f",
      "value": " 100/100 [00:24&lt;00:00,  4.91it/s]"
     }
    },
    "b7d303b547924163acb02c690cfac7c7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3fb3e0fe97e54db99c0532a66911bc84",
       "IPY_MODEL_1add1e8945964e189c63557224b740fc",
       "IPY_MODEL_96bdac24271c490caeafed06be53e2fd"
      ],
      "layout": "IPY_MODEL_81ff9d16b3624054984a94baf2998fad"
     }
    },
    "bb65e7a00bbb44c6aa1ec72f33b64221": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c0774078b6954b58afa08a657c648e37": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c575ac2e09424c3f8fc76c924b1314f4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4c2e235e63d64196964deec526f3784c",
      "placeholder": "​",
      "style": "IPY_MODEL_bb65e7a00bbb44c6aa1ec72f33b64221",
      "value": "100%"
     }
    },
    "c6d702c50e9840e69a9e75caf2bdb4b0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e6f3d7eb344d40a4b9fd97a3617a94f9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ec425fa026f84d359130572ee193b14f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f3fc925008d64eb3af346326f11737cf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
