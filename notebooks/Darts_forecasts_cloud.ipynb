{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62c18b4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c62c18b4",
    "outputId": "76fbe2fe-68b5-40ec-9297-b754f070b96f"
   },
   "outputs": [],
   "source": [
    "# pip install watermark lightgbm plotly cufflinks numpy pandas optuna torch pandas_ta gluonts pandas_datareader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "s2Q0FzF2JQIh",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "s2Q0FzF2JQIh",
    "outputId": "6b445e27-33e1-4bd5-899a-98f839863736"
   },
   "outputs": [],
   "source": [
    "# pip install -U git+https://github.com/unit8co/darts.git@master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129ffc3c",
   "metadata": {
    "id": "129ffc3c"
   },
   "outputs": [],
   "source": [
    "# 1. magic for inline plot\n",
    "# 2. magic to print version\n",
    "# 3. magic so that the notebook will reload external python modules\n",
    "# 4. magic to enable retina (high resolution) plots\n",
    "# https://gist.github.com/minrk/3301035\n",
    "%matplotlib inline\n",
    "%reload_ext watermark\n",
    "%config InlineBackend.figure_format='retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df345767",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "df345767",
    "outputId": "c1dfac25-33b8-48e7-e9bf-34341033439e"
   },
   "outputs": [],
   "source": [
    "%watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364f8efb",
   "metadata": {
    "id": "364f8efb"
   },
   "outputs": [],
   "source": [
    "# conda install -c conda-forge 'u8darts'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e31e795",
   "metadata": {
    "id": "8e31e795"
   },
   "source": [
    "### Library imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b05fbe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "81b05fbe",
    "outputId": "b6141785-035e-47ba-c0e2-150468a163e2"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import darts\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# pip install matplotlib==3.1.2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import plotly.offline\n",
    "import cufflinks as cf\n",
    "cf.go_offline()\n",
    "cf.set_config_file(offline=False, world_readable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f755d351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -U \"u8darts[torch]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c94ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "darts.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e94c945",
   "metadata": {
    "id": "2e94c945"
   },
   "source": [
    "### Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78e90ff",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a78e90ff",
    "outputId": "62d47171-1ec1-47e5-9d65-f98078071113"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(0)\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "\n",
    "import torch\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424cdf80",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "id": "424cdf80",
    "outputId": "9548de8a-12cd-46da-f3f6-bdefbfadb8d0"
   },
   "outputs": [],
   "source": [
    "df_m6 = pd.read_csv(\"M6_Universe.csv\", index_col=0)\n",
    "df_m6.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a499885a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks = df_m6[df_m6[\"class\"]==\"Stock\"][\"symbol\"].values\n",
    "etfs = df_m6[df_m6[\"class\"]==\"ETF\"][\"symbol\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216285c9",
   "metadata": {
    "id": "216285c9"
   },
   "outputs": [],
   "source": [
    "SAMPLE_SIZE = 100\n",
    "FORECAST_HORIZON = 28 #days\n",
    "PERIODS = 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a73d1cc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86,
     "referenced_widgets": [
      "b7d303b547924163acb02c690cfac7c7",
      "81ff9d16b3624054984a94baf2998fad",
      "3fb3e0fe97e54db99c0532a66911bc84",
      "1add1e8945964e189c63557224b740fc",
      "96bdac24271c490caeafed06be53e2fd",
      "f3fc925008d64eb3af346326f11737cf",
      "073685966c774b01953c0343bef00251",
      "c0774078b6954b58afa08a657c648e37",
      "4c3eb9334739464aaa3ef7b87c6369ac",
      "ec425fa026f84d359130572ee193b14f",
      "742a3ef153ee4c1fa4a7ced4c899c0e0"
     ]
    },
    "id": "7a73d1cc",
    "outputId": "da93f97c-de29-45a8-e6db-22020c88a06a"
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from utils import get_ticker_historical_data\n",
    "import pandas_datareader as pdr\n",
    "\n",
    "directory = './tickers'\n",
    "save = False\n",
    "\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "tickers = df_m6[\"symbol\"].to_list()\n",
    "tickers_data = dict()\n",
    "from_date = pd.to_datetime(\"2000-01-01\")\n",
    "\n",
    "to_date = pd.Timestamp.today()\n",
    "to_date.tz_localize(tz='Europe/Moscow').tz_convert(tz='America/New_York')\n",
    "to_date.replace(hour=0, minute=0, second=0, microsecond=0)\n",
    "\n",
    "to_date = pd.to_datetime(\"2022-05-01\")\n",
    "interval = '1d'\n",
    "\n",
    "for ticker in tqdm(tickers[:SAMPLE_SIZE]): \n",
    "#     data = get_ticker_historical_data(ticker=ticker,\n",
    "#                                       from_date=from_date,\n",
    "#                                       to_date=to_date,\n",
    "#                                       interval=interval\n",
    "#                                       )\n",
    "    # This returns a data frame of scraped stock data from yahoo\n",
    "    data = pdr.DataReader(ticker, 'yahoo', from_date, to_date)\n",
    "    tickers_data[ticker] = data\n",
    "    if save:\n",
    "        data.reset_index().to_csv(os.path.join(directory,f'{ticker}_{interval}.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b7ef24",
   "metadata": {
    "id": "07b7ef24"
   },
   "outputs": [],
   "source": [
    "def calculate_pct_returns(x: pd.Series, periods: int) -> pd.Series:\n",
    "    return (1 + x.pct_change(periods=periods))\n",
    "\n",
    "def calculate_cum_pct_returns(x: pd.Series, periods: int) -> pd.Series:\n",
    "    return (((1 + x.pct_change(periods=periods)).cumprod() - 1))*100\n",
    "\n",
    "def calculate_cum_log_returns(x: pd.Series, periods: int) -> pd.Series:\n",
    "    return (np.log(1 + x.pct_change(periods=periods)).cumsum())\n",
    "\n",
    "def calculate_log_returns(x: pd.Series, periods: int) -> pd.Series:\n",
    "    return np.log(1 + x.pct_change(periods=periods))\n",
    "\n",
    "df = pd.DataFrame.from_dict({k: v['Adj Close'] for k, v in tickers_data.items()})\n",
    "df_stock_cum_log_returns = df.apply(calculate_cum_log_returns, periods=PERIODS, axis=0)\n",
    "df_stock_cum_prt_returns = df.apply(calculate_cum_pct_returns, periods=PERIODS, axis=0)\n",
    "df_stock_log_returns = df.apply(calculate_log_returns, periods=PERIODS, axis=0)\n",
    "df_stock_prc_returns = df.apply(calculate_pct_returns, periods=PERIODS, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8cb4233",
   "metadata": {
    "id": "c8cb4233"
   },
   "outputs": [],
   "source": [
    "df_stock_returns = df_stock_prc_returns.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7209a62",
   "metadata": {},
   "source": [
    "#### Predicting Ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e9d68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_stock_returns_quantiles = df_stock_returns.dropna().apply(lambda x: (x.rank(ascending=True) // 20 +1).clip(upper=5), axis=0).astype(int)\n",
    "# for ticket in df_stock_returns_quantiles.columns:\n",
    "#     df_stock_returns_quantiles[[ticket]].plot()#(kind='hist')\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4dd6f66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "895b84c0",
   "metadata": {
    "id": "895b84c0"
   },
   "source": [
    "### Reindex dates and fill in with previous values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c4768f",
   "metadata": {
    "id": "c7c4768f"
   },
   "outputs": [],
   "source": [
    "from gluonts.time_feature.holiday import (\n",
    "    squared_exponential_kernel,\n",
    "    SpecialDateFeatureSet,\n",
    "    NEW_YEARS_DAY,\n",
    "    MARTIN_LUTHER_KING_DAY,\n",
    "    PRESIDENTS_DAY,\n",
    "    GOOD_FRIDAY,\n",
    "    MEMORIAL_DAY,\n",
    "    INDEPENDENCE_DAY,\n",
    "    LABOR_DAY,\n",
    "    THANKSGIVING,\n",
    "    CHRISTMAS_DAY,\n",
    "    SUPERBOWL,\n",
    "    CHRISTMAS_EVE,\n",
    "    EASTER_SUNDAY,\n",
    "    EASTER_MONDAY,\n",
    "    MOTHERS_DAY,\n",
    "    COLUMBUS_DAY,\n",
    "    NEW_YEARS_EVE,\n",
    "    BLACK_FRIDAY,\n",
    "    CYBER_MONDAY\n",
    ")\n",
    "\n",
    "# Example use for using a squared exponential kernel:\n",
    "kernel = squared_exponential_kernel(alpha=1.0)\n",
    "sfs = SpecialDateFeatureSet([NEW_YEARS_DAY,\n",
    "                             MARTIN_LUTHER_KING_DAY,\n",
    "                             PRESIDENTS_DAY,\n",
    "                             GOOD_FRIDAY,\n",
    "                             MEMORIAL_DAY,\n",
    "                             INDEPENDENCE_DAY,\n",
    "                             LABOR_DAY,\n",
    "                             THANKSGIVING,\n",
    "                             CHRISTMAS_DAY],\n",
    "                            kernel)\n",
    "\n",
    "sfs2 = SpecialDateFeatureSet([SUPERBOWL,\n",
    "                              CHRISTMAS_EVE,\n",
    "                              EASTER_SUNDAY,\n",
    "                              EASTER_MONDAY,\n",
    "                              MOTHERS_DAY,\n",
    "                              COLUMBUS_DAY,\n",
    "                              NEW_YEARS_EVE,\n",
    "                              BLACK_FRIDAY,\n",
    "                              CYBER_MONDAY],\n",
    "                            kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17b8aed",
   "metadata": {
    "id": "d17b8aed"
   },
   "outputs": [],
   "source": [
    "import pandas_ta as ta\n",
    "\n",
    "# Create our own Custom Strategy\n",
    "CustomStrategy = ta.Strategy(\n",
    "    name=\"Momo and Volatility\",\n",
    "    description=\"SMA 50,200, BBANDS, RSI, MACD and Volume SMA 20\",\n",
    "    ta=[\n",
    "        {\"kind\": \"sma\", \"length\": 20, \"close\": \"Adj Close\"},\n",
    "        {\"kind\": \"sma\", \"length\": 5, \"close\": \"Adj Close\"},\n",
    "        #{\"kind\": \"sma\", \"length\": 200, \"close\": \"Adj Close\"},\n",
    "        {\"kind\": \"ema\", \"length\": 8, \"close\": \"Adj Close\"},\n",
    "        {\"kind\": \"ema\", \"length\": 21, \"close\": \"Adj Close\"},\n",
    "#         {\"kind\": \"ema\", \"length\": 50, \"close\": \"Adj Close\"},\n",
    "        {\"kind\": \"bbands\", \"length\": 20, \"close\": \"Adj Close\"},\n",
    "        {\"kind\": \"rsi\", \"close\": \"Adj Close\"},\n",
    "        {\"kind\": \"stochrsi\", \"length\": 14, \"close\": \"Adj Close\"},\n",
    "        {\"kind\": \"macd\", \"fast\": 8, \"slow\": 21, \"close\": \"Adj Close\"},\n",
    "        {\"kind\": \"stoch\", \"fast\": 9, \"slow\": 6, \"close\": \"Adj Close\"},\n",
    "        {\"kind\": \"macd\", \"fast\": 12, \"slow\": 26, \"close\": \"Adj Close\"},\n",
    "        {\"kind\": \"sma\", \"close\": \"Volume\", \"length\": 20, \"prefix\": \"Volume\"},\n",
    "    ]\n",
    ")\n",
    "\n",
    "# calculate different KPI\n",
    "def upper_shadow(df): return df['High'] - np.maximum(df['Close'], df['Open'])\n",
    "def lower_shadow(df): return np.minimum(df['Close'], df['Open']) - df['Low']\n",
    "                \n",
    "def upper_shadow_percent(df): return (df['High'] / np.maximum(df['Close'], df['Open'])) -1\n",
    "def lower_shadow_percent(df): return (np.minimum(df['Close'], df['Open']) / df['Low']) -1\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87ffa35",
   "metadata": {
    "id": "f87ffa35"
   },
   "outputs": [],
   "source": [
    "# Make a pipeline with the steps\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion, make_pipeline\n",
    "from transformers import DateTimeTransformer, periodic_spline_transformer\n",
    "from reduce_memory import ReduceMemoryTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "date_time_transforms = make_pipeline(\n",
    "    DateTimeTransformer()\n",
    ")\n",
    "\n",
    "memory_transforms = make_pipeline(\n",
    "    ReduceMemoryTransformer()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed25ec6",
   "metadata": {
    "id": "0ed25ec6"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from nyse_holidays import NYSECalendar\n",
    "\n",
    "def get_datetime_covariates(start_index, end_index):\n",
    "    calendar = NYSECalendar()\n",
    "    index = pd.date_range(start=start_index, end=end_index, freq='D')\n",
    "    holiday_dates = calendar.holidays(start_index, end_index, return_name=True).index\n",
    "    covariates = pd.DataFrame(index=index)\n",
    "    covariates.loc[:, ['one_hot_weekends', 'one_hot_holidays']] = 0\n",
    "    covariates.loc[covariates.index.isin(holiday_dates), 'one_hot_holidays'] = 1 \n",
    "    covariates.loc[covariates.index.day_name().isin(['Saturday', 'Sunday']),'one_hot_weekends'] = 1\n",
    "    covariates.loc[:,'kernel_holidays'] = sfs(covariates.index).max(axis=0) # np.prod(sfs(covariates.index), axis=1)\n",
    "    covariates.loc[:,'kernel_other_holidays'] = sfs2(covariates.index).max(axis=0)\n",
    "    covariates = covariates.round(3)\n",
    "\n",
    "    covariates = date_time_transforms.fit_transform(covariates)\n",
    "    month_splines = periodic_spline_transformer(12, n_splines=6).fit_transform(covariates[['month']])\n",
    "    weekday_splines = periodic_spline_transformer(7, n_splines=3).fit_transform(covariates[['day_of_week']])\n",
    "    splines = np.concatenate((month_splines, weekday_splines), axis=1)\n",
    "    spline_names = [f\"spline_{i}\" for i in range(splines.shape[1])]\n",
    "    covariates.loc[:, spline_names] = splines\n",
    "    covariates = memory_transforms.fit_transform(covariates)\n",
    "    \n",
    "    scaler = MinMaxScaler() #StandardScaler()\n",
    "    covariates = pd.DataFrame(data=scaler.fit_transform(covariates), \n",
    "                              index=covariates.index, \n",
    "                              columns=covariates.columns)\n",
    "\n",
    "    return covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732bf209",
   "metadata": {
    "id": "732bf209"
   },
   "outputs": [],
   "source": [
    "start_index = df_stock_returns.index[0]\n",
    "end_index = df_stock_returns.index[-1]\n",
    "# end_index = pd.Timestamp(\"2022-03-06\") \n",
    "df_stock_returns = (df_stock_returns\n",
    "        .reindex(pd.date_range(start=start_index, end=end_index, freq='D'))\n",
    "        .fillna(method='ffill')\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2eb6583",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a2eb6583",
    "outputId": "40c94018-fa20-4b6d-f386-8e766c73081f"
   },
   "outputs": [],
   "source": [
    "covariates = get_datetime_covariates(start_index, end_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012199ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(df_m6[[\"GICS_sector/ETF_type\"]].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440815db",
   "metadata": {},
   "outputs": [],
   "source": [
    ", "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e61c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le_sector = preprocessing.LabelEncoder()\n",
    "le_sector.fit(np.unique(df_m6[[\"GICS_sector/ETF_type\"]].values))\n",
    "le_industry = preprocessing.LabelEncoder()\n",
    "le_industry.fit(np.unique(df_m6[[\"GICS_industry/ETF_subtype\"]].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36d157b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d36d157b",
    "outputId": "07fb0ac2-5688-4a96-ff8f-ad762a51e473"
   },
   "outputs": [],
   "source": [
    "tickers_data_enriched = {}\n",
    "\n",
    "for k, v in tickers_data.items():\n",
    "    df = v.copy()\n",
    "    df.ta.strategy(CustomStrategy)\n",
    "    df.ta.percent_return(cumulative=False, append=True)\n",
    "#     df.ta.percent_return(cumulative=False, length=PERIODS, append=True)\n",
    "    df = (df\n",
    "        .reindex(pd.date_range(start=df.index[0], end=end_index, freq='D'))\n",
    "        .fillna(method='ffill')\n",
    "        .fillna(method='bfill')\n",
    "    )\n",
    "    df['high2low'] = df['High'] / df['Low']\n",
    "    df['std'] = df['Adj Close'].std()\n",
    "    df['var'] = df['Adj Close'].var()\n",
    "\n",
    "    df[f\"cum_log_returns_{PERIODS}\"] = df[[\"Adj Close\"]].apply(calculate_cum_log_returns, periods=PERIODS, axis=0).values\n",
    "    df[f\"log_returns_{PERIODS}\"] = df[[\"Adj Close\"]].apply(calculate_log_returns, periods=PERIODS, axis=0).values\n",
    "    df['std'] = df['Adj Close'].std()\n",
    "    df['var'] = df['Adj Close'].var()\n",
    "    df['upper_shadow'] = upper_shadow(df)\n",
    "    df['lower_shadow'] = lower_shadow(df)\n",
    "    df['upper_shadow_percent'] = upper_shadow_percent(df)\n",
    "    df['lower_shadow_percent'] = lower_shadow_percent(df)    \n",
    "    \n",
    "    df[\"GICS_sector/ETF_type\"] = le_sector.transform(df_m6[df_m6[\"symbol\"]==k][\"GICS_sector/ETF_type\"].values)[0]\n",
    "    df[\"GICS_industry/ETF_subtype\"] = le_industry.transform(df_m6[df_m6[\"symbol\"]==k][\"GICS_industry/ETF_subtype\"].values)[0]\n",
    "    #     df[\"group\"] = k\n",
    "    df[\"ticket\"] = 1 if k in stocks else 0\n",
    "    df[\"log_volume\"] = np.log(df[\"Volume\"] + 1e-8)\n",
    "    \n",
    "    df = memory_transforms.fit_transform(df)\n",
    "\n",
    "    scaler = MinMaxScaler() #StandardScaler()\n",
    "    df_scaled = pd.DataFrame(data=scaler.fit_transform(df), \n",
    "                             index=df.index,\n",
    "                             columns=df.columns)\n",
    "    df_scaled.dropna(inplace=True)\n",
    "    tickers_data_enriched[k] = df_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f2d559",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "5b705b8c225d4d76b46b50c9f510a40e",
      "86f69349b4b94dc68923fbcd72d1a2b1",
      "c575ac2e09424c3f8fc76c924b1314f4",
      "08db2b9a48c542adbe8cc7e06bb31871",
      "53173af3160b4b758ed2c33d3b554008",
      "bb65e7a00bbb44c6aa1ec72f33b64221",
      "4c2e235e63d64196964deec526f3784c",
      "4d8362c0442e446abcd1f36928c2b8e9",
      "c6d702c50e9840e69a9e75caf2bdb4b0",
      "e6f3d7eb344d40a4b9fd97a3617a94f9",
      "75bdf511cc3242eaae63569a7d40f4b6"
     ]
    },
    "id": "65f2d559",
    "outputId": "d292ec01-94f0-4b6c-e13b-a423e6bf0883"
   },
   "outputs": [],
   "source": [
    "from darts import TimeSeries\n",
    "from darts.dataprocessing.transformers import (\n",
    "    Scaler,\n",
    "    MissingValuesFiller,\n",
    "    Mapper,\n",
    "    InvertibleMapper,\n",
    ")\n",
    "scaled_series = list()\n",
    "future_covariates = list()\n",
    "past_covariates = list()\n",
    "scalers = list()\n",
    "\n",
    "for column in tqdm(df_stock_returns.columns): \n",
    "    df = df_stock_returns[[column]].copy()\n",
    "    scaler = Scaler()\n",
    "    filler = MissingValuesFiller()\n",
    "    \n",
    "    df.dropna(axis=0, inplace=True)\n",
    "    future_cov = covariates.copy()\n",
    "    future_cov = future_cov.loc[df.index[0]:df.index[-1],:]\n",
    "    \n",
    "    past_cov = tickers_data_enriched[column].copy()\n",
    "    past_cov = past_cov.loc[df.index[0]:df.index[-1],:]\n",
    "\n",
    "    serie = TimeSeries.from_dataframe(df.reset_index(), \n",
    "                                      time_col='index',\n",
    "                                      fill_missing_dates=False,\n",
    "                                      freq='D'\n",
    "                                     )\n",
    "    scaled_serie = scaler.fit_transform(serie)\n",
    "    filled = filler.transform(scaled_serie, method=\"quadratic\")\n",
    "    \n",
    "    past_cov_series = TimeSeries.from_dataframe(past_cov.reset_index(), \n",
    "                                                time_col='index',\n",
    "                                                fill_missing_dates=False,\n",
    "                                                freq='D'\n",
    "                                                )\n",
    "    future_cov_series = TimeSeries.from_dataframe(future_cov.reset_index(), \n",
    "                                                  time_col='index',\n",
    "                                                  fill_missing_dates=False,\n",
    "                                                  freq='D'\n",
    "                                                 )\n",
    "    \n",
    "    scalers.append(scaler)\n",
    "    scaled_series.append(filled)\n",
    "    future_covariates.append(future_cov_series)\n",
    "    past_covariates.append(past_cov_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94a8453",
   "metadata": {
    "id": "c94a8453"
   },
   "outputs": [],
   "source": [
    "# from darts.utils.statistics import plot_acf, check_seasonality\n",
    "\n",
    "# for serie in scaled_series[:1]:\n",
    "#     plot_acf(serie, m=125, alpha=0.05, max_lag=540)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f093a571",
   "metadata": {
    "id": "f093a571"
   },
   "outputs": [],
   "source": [
    "# for serie in scaled_series:\n",
    "#     for m in range(2, 25):\n",
    "#         is_seasonal, period = check_seasonality(serie, m=m, alpha=0.05)\n",
    "#         if is_seasonal:\n",
    "#             print(\"There is seasonality of order {}.\".format(period))\n",
    "#     print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14f7084",
   "metadata": {
    "id": "e14f7084"
   },
   "outputs": [],
   "source": [
    "# [serie.plot() for serie in scaled_series[:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3205d5a",
   "metadata": {
    "id": "f3205d5a"
   },
   "outputs": [],
   "source": [
    "# scaled_series[0].pd_dataframe()\n",
    "# scaled_series[0].values()\n",
    "# scaled_series[0].all_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dacf854",
   "metadata": {
    "id": "3dacf854"
   },
   "source": [
    "### Future covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6acb183d",
   "metadata": {
    "id": "6acb183d"
   },
   "outputs": [],
   "source": [
    "# from darts import concatenate\n",
    "# from darts.utils.timeseries_generation import datetime_attribute_timeseries as dt_attr\n",
    "# from darts.utils.timeseries_generation import holidays_timeseries as holiday_attr\n",
    "# from darts.utils.timeseries_generation import linear_timeseries\n",
    "\n",
    "# future_covs = [concatenate(\n",
    "#                         [\n",
    "#                             dt_attr(series.time_index, \"month\", one_hot=True, dtype=np.float32),\n",
    "#                             #dt_attr(series.time_index, \"month\", cyclic=True, dtype=np.float32),\n",
    "#                             dt_attr(series.time_index, \"week\", one_hot=True, dtype=np.float32),\n",
    "#                             #dt_attr(series.time_index, \"week\", cyclic=True, dtype=np.float32),\n",
    "#                             dt_attr(series.time_index, \"weekday\", one_hot=True, dtype=np.float32),\n",
    "#                             #dt_attr(series.time_index, \"weekday\", cyclic=True, dtype=np.float32),\n",
    "#                             dt_attr(series.time_index, \"day\", one_hot=True, dtype=np.float32),\n",
    "#                             #dt_attr(series.time_index, \"day\", cyclic=True, dtype=np.float32),\n",
    "#                             (dt_attr(series.time_index, \"year\", dtype=np.float32) - 2000) / 12,\n",
    "#                             holiday_attr(series.time_index, country_code=\"US\", dtype=np.float32),\n",
    "#                             linear_timeseries(start=series.time_index[0], end=series.time_index[-1], dtype=np.float32)\n",
    "#                         ],\n",
    "#                             axis=\"component\",\n",
    "#                         ) for series in scaled_series]\n",
    "\n",
    "# future_covs = [concatenate(\n",
    "#                         [\n",
    "#                             dt_attr(series.time_index, \"month\", cyclic=True, dtype=np.float32),\n",
    "#                             dt_attr(series.time_index, \"week\", cyclic=True, dtype=np.float32),\n",
    "#                             dt_attr(series.time_index, \"weekday\", cyclic=True, dtype=np.float32),\n",
    "#                             dt_attr(series.time_index, \"day_of_week\", cyclic=True, dtype=np.float32),\n",
    "#                             (dt_attr(series.time_index, \"year\", dtype=np.float32) - 2000) / 12,\n",
    "#                             holiday_attr(series.time_index, country_code=\"US\", dtype=np.float32),\n",
    "#                             linear_timeseries(start=series.time_index[0], end=series.time_index[-1], dtype=np.float32)\n",
    "#                         ],\n",
    "#                             axis=\"component\",\n",
    "#                         ) for series in scaled_series]\n",
    "\n",
    "# future_covs.plot()\n",
    "# plt.title(\n",
    "#     \"one multivariate time series of 2 dimensions, containing covariates for the air series:\"\n",
    "# );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b709e3",
   "metadata": {
    "id": "89b709e3"
   },
   "outputs": [],
   "source": [
    "forecast_horizon = 28\n",
    "start_split = 0.8\n",
    "input_chunk_length = 28\n",
    "quantiles = [0.05, 0.5, 0.95]\n",
    "\n",
    "splited_series = [serie.split_before(start_split) for serie in scaled_series] # if serie.n_timesteps > 500]\n",
    "splited_past_covariates = [serie.split_before(start_split) for serie in past_covariates]\n",
    "splited_future_covariates = [serie.split_before(start_split) for serie in future_covariates]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f617c1",
   "metadata": {
    "id": "42f617c1"
   },
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from utils import print_error_metrics\n",
    "from darts.metrics import mape, r2_score, mse, rmse, mae\n",
    "import matplotlib.pyplot as plt \n",
    "from tqdm import tqdm\n",
    "\n",
    "def backtest_local_models(models, \n",
    "                          scaled_series, \n",
    "                          past_covariates, \n",
    "                          future_covariates,\n",
    "                          forecast_horizon, \n",
    "                          start_split,\n",
    "                          verbose=False) -> List:\n",
    "    backtests = [model.historical_forecasts(series=serie,\n",
    "                                            past_covariates=past_cov,\n",
    "                                            future_covariates=future_cov,\n",
    "                                            forecast_horizon=forecast_horizon,\n",
    "                                            start=start_split,\n",
    "                                            stride=1,\n",
    "                                            retrain=False,\n",
    "                                            last_points_only=True,\n",
    "                                            overlap_end=True,\n",
    "                                            verbose=verbose)\n",
    "                 for model, serie, past_cov, future_cov in tqdm(list(zip(models, \n",
    "                                                                    scaled_series, \n",
    "                                                                    past_covariates, \n",
    "                                                                    future_covariates)))]\n",
    "    return backtests\n",
    "\n",
    "def backtest_global_model(model, \n",
    "                          scaled_series, \n",
    "                          past_covariates, \n",
    "                          future_covariates,\n",
    "                          forecast_horizon, \n",
    "                          start_split,\n",
    "                          verbose=False) -> List:\n",
    "    backtests = [model.historical_forecasts(series=serie,\n",
    "                                            past_covariates=past_cov,\n",
    "                                            future_covariates=future_cov,\n",
    "                                            forecast_horizon=forecast_horizon,\n",
    "                                            start=start_split,\n",
    "                                            stride=1,\n",
    "                                            num_samples=100,\n",
    "                                            retrain=False,\n",
    "                                            last_points_only=True,\n",
    "                                            overlap_end=False,\n",
    "                                            verbose=verbose)\n",
    "                 for serie, past_cov, future_cov in tqdm(list(zip(scaled_series, \n",
    "                                                             past_covariates, \n",
    "                                                             future_covariates)))]\n",
    "    return backtests\n",
    "\n",
    "def fit_local_models(models, \n",
    "                     scaled_series, \n",
    "                     past_covariates, \n",
    "                     future_covariates) -> List:\n",
    "    for model, serie, past_cov, future_cov in tqdm(list(zip(models, \n",
    "                                                       scaled_series, \n",
    "                                                       past_covariates, \n",
    "                                                       future_covariates))):\n",
    "        model.fit(series=serie[0], \n",
    "                  past_covariates=past_cov[0],\n",
    "                  future_covariates=future_cov[0],\n",
    "             )\n",
    "    return models\n",
    "\n",
    "def full_fit_local_models(models, \n",
    "                          scaled_series, \n",
    "                          past_covariates, \n",
    "                          future_covariates) -> List:\n",
    "    for model, serie, past_cov, future_cov in tqdm(list(zip(models, \n",
    "                                                            scaled_series, \n",
    "                                                            past_covariates, \n",
    "                                                            future_covariates))):\n",
    "        model.fit(series=serie, \n",
    "                  past_covariates=past_cov,\n",
    "                  future_covariates=future_cov,\n",
    "             )\n",
    "    return models\n",
    "\n",
    "def predict_local_models(models,\n",
    "                         forecast_horizon,\n",
    "                         past_covariates, \n",
    "                         future_covariates) -> List:\n",
    "    predictions = [model.predict(\n",
    "                          n=forecast_horizon,\n",
    "                          past_covariates=past_cov,\n",
    "                          future_covariates=future_cov\n",
    "                          ) for model, past_cov, future_cov in tqdm(list(zip(models, \n",
    "                                                                        past_covariates, \n",
    "                                                                        future_covariates)))]\n",
    "    return predictions\n",
    "\n",
    "def predict_global_model(model,\n",
    "                         targets,\n",
    "                         forecast_horizon,\n",
    "                         past_covariates, \n",
    "                         future_covariates) -> List:\n",
    "    predictions = [model.predict(\n",
    "                          n=forecast_horizon,\n",
    "                          past_covariates=past_cov,\n",
    "                          future_covariates=future_cov\n",
    "                          ) for targets, past_cov, future_cov in tqdm(list(zip(targets, \n",
    "                                                                          past_covariates, \n",
    "                                                                          future_covariates)))]\n",
    "    return predictions\n",
    "\n",
    "def fit_global_model(model, \n",
    "                     scaled_series, \n",
    "                     past_covariates, \n",
    "                     future_covariates) -> List:\n",
    "    for serie, past_cov, future_cov in tqdm(list(zip(scaled_series, \n",
    "                                                past_covariates, \n",
    "                                                future_covariates))):\n",
    "        model.fit(series=serie[0], \n",
    "                  past_covariates=past_cov[0],\n",
    "                  future_covariates=future_cov[0]\n",
    "                 )\n",
    "    return model\n",
    "\n",
    "def calculate_loss(scalers, \n",
    "                   splited_series, \n",
    "                   backtests,\n",
    "                   log=False,\n",
    "                   scaling=False) -> float:\n",
    "    rmse_losses = list()\n",
    "    mae_losses = list()\n",
    "    for scaler, serie_list, backtest in tqdm(list(zip(scalers, splited_series, backtests))):\n",
    "        \n",
    "        val_serie = serie_list[1]\n",
    "        \n",
    "        if scaling:\n",
    "            val_serie = scaler.inverse_transform(val_serie)\n",
    "            backtest = scaler.inverse_transform(backtest)            \n",
    "\n",
    "        if log:\n",
    "            val_serie = val_serie.map(lambda x: (np.exp(x) - 1))\n",
    "            backtest = backtest.map(lambda x: (np.exp(x) - 1))\n",
    "\n",
    "        rmse_losses.append(\n",
    "            rmse(val_serie.slice_intersect(backtest), backtest)\n",
    "        )\n",
    "        mae_losses.append(\n",
    "            mae(val_serie.slice_intersect(backtest), backtest)\n",
    "        )\n",
    "    mean_rmse, std_rmse = np.mean(rmse_losses), np.std(rmse_losses)\n",
    "    mean_mae, std_mae = np.mean(mae_losses), np.std(mae_losses)\n",
    "    print(f\"rmse_mean = {mean_rmse}, rmse_std = {std_rmse}\")\n",
    "    print(f\"mae_mean = {mean_mae}, mae_std = {std_mae}\")\n",
    "    return mean_rmse\n",
    "    \n",
    "def inverse_forecasts(scalers, forecasts, log=False):\n",
    "    scaled_forecasts = []\n",
    "    for scaler, forecast in list(zip(scalers, forecasts)):\n",
    "        forecast = scaler.inverse_transform(forecast)\n",
    "        if log:\n",
    "            forecast = forecast.map(lambda x: (np.exp(x) - 1))\n",
    "        scaled_forecasts.append(forecast)\n",
    "    return scaled_forecasts\n",
    "\n",
    "\n",
    "def get_residuals(scalers, forecasts, series, log=False):\n",
    "    residuals = []\n",
    "    for scaler, forecast, serie in tqdm(list(zip(scalers, forecasts, series))):\n",
    "        forecast = scaler.inverse_transform(forecast)\n",
    "        serie = scaler.inverse_transform(serie)\n",
    "        \n",
    "        if log:\n",
    "            forecast = forecast.map(lambda x: (np.exp(x) - 1))\n",
    "            serie = serie.map(lambda x: (np.exp(x) - 1))\n",
    "\n",
    "        residuals.append(\n",
    "            (forecast - serie.slice_intersect(forecast)).pd_dataframe()\n",
    "        )\n",
    "    return residuals\n",
    "\n",
    "def plot_prediction_forecasts(scalers, series, forecasts, slicing=True, log=False, scaling=False) -> None:\n",
    "    for scaler, serie, forecast in tqdm(list(zip(scalers, series, forecasts))):\n",
    "        \n",
    "        if scaling:\n",
    "            serie = scaler.inverse_transform(serie)\n",
    "            forecast = scaler.inverse_transform(forecast)\n",
    "\n",
    "        if log:\n",
    "            serie = serie.map(lambda x: (np.exp(x) - 1))\n",
    "            forecast = forecast.map(lambda x: (np.exp(x) - 1))\n",
    "\n",
    "        if slicing:\n",
    "            serie.slice_intersect(forecast).plot(label='data')\n",
    "        else:\n",
    "            serie.plot(label='data')\n",
    "        forecast.plot(lw=2, label='forecast')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "def plot_backtest_forecasts(scalers, splited_series, backtests, slicing=True, log=False, scaling=False) -> None:\n",
    "    for scaler, serie_list, backtest in tqdm(list(zip(scalers, splited_series, backtests))):\n",
    "        val_serie = serie_list[1]\n",
    "        \n",
    "        if scaling:\n",
    "            val_serie = scaler.inverse_transform(val_serie)\n",
    "            backtest = scaler.inverse_transform(backtest)\n",
    "\n",
    "        if log:\n",
    "            val_serie = val_serie.map(lambda x: (np.exp(x) - 1))\n",
    "            backtest = backtest.map(lambda x: (np.exp(x) - 1))\n",
    "\n",
    "        if slicing:\n",
    "            val_serie.slice_intersect(backtest).plot(label='data')\n",
    "        else:\n",
    "            val_serie.plot(label='data')\n",
    "\n",
    "        backtest.plot(lw=2, label='forecast')\n",
    "        #covs.slice_intersect(backtest)[:slice_size].plot(label='covariates')\n",
    "        #error = print_error_metrics(val_serie.slice_intersect(backtest).values(), backtest.values())\n",
    "\n",
    "        #plt.title(f' MAE: {mae(val_serie,backtest)}, RMSE: {rmse(val_serie, backtest)}')\n",
    "        #plt.title(error)\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5919d8e",
   "metadata": {
    "id": "d5919d8e"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f982eff",
   "metadata": {
    "id": "3f982eff"
   },
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import RidgeCV\n",
    "# from darts.models.forecasting.regression_ensemble_model import RegressionEnsembleModel\n",
    "# from darts.utils.utils import ModelMode, SeasonalityMode\n",
    "# from darts.models import Theta, RegressionModel, ExponentialSmoothing\n",
    "\n",
    "# stat_models = [RegressionEnsembleModel(\n",
    "#                                 forecasting_models=[\n",
    "#                                                     ExponentialSmoothing(trend=ModelMode.ADDITIVE, \n",
    "#                                                                          seasonal=SeasonalityMode.NONE,\n",
    "#                                                                          seasonal_periods=7,\n",
    "#                                                                         ), \n",
    "#                                                     Theta(theta=2, \n",
    "#                                                           seasonality_period=7, \n",
    "#                                                           season_mode=SeasonalityMode.ADDITIVE\n",
    "#                                                     )\n",
    "#                                                    ], \n",
    "#                                 regression_train_n_points=int(len(scaled_series[0])*0.5*(1-start_split)),\n",
    "#                                 regression_model=KernelRidge()\n",
    "# ) \n",
    "#                 for model in range(len(scaled_series))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633cf667",
   "metadata": {
    "id": "633cf667"
   },
   "source": [
    "### Model per series "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83efe997",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "83efe997",
    "outputId": "86f0b5c2-4e6b-49e7-d2c2-2d4982d01370"
   },
   "outputs": [],
   "source": [
    "from darts.models.forecasting.gradient_boosted_model import LightGBMModel\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor, StackingRegressor\n",
    "from darts.models import RegressionModel\n",
    "# from darts.models.forecasting.regression_model import RegressionModel\n",
    "\n",
    "from sklearn.linear_model import (RidgeCV, \n",
    "                                  #TweedieRegressor, \n",
    "                                  SGDRegressor, \n",
    "                                  LassoCV, \n",
    "                                  HuberRegressor, \n",
    "                                  ElasticNetCV,\n",
    "                                  #BayesianRidge,\n",
    "                                 )\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.svm import SVR, LinearSVR, NuSVR\n",
    "\n",
    "# init the models \n",
    "models = [RegressionModel(lags=forecast_horizon, \n",
    "                          lags_past_covariates=forecast_horizon,\n",
    "                          lags_future_covariates=(int(forecast_horizon/2),7),\n",
    "                          output_chunk_length=forecast_horizon,\n",
    "                          model=RidgeCV()#(l1_ratio=0.4),\n",
    "                          \n",
    "                         )\n",
    "          for model in range(len(scaled_series))]\n",
    "\n",
    "# models = [LightGBMModel(lags=7, \n",
    "#                         lags_past_covariates=7,\n",
    "#                         lags_future_covariates=(7,2),\n",
    "#                         output_chunk_length=forecast_horizon\n",
    "      \n",
    "#                          )\n",
    "#           for model in range(len(scaled_series))]\n",
    "\n",
    "model = RegressionModel(lags=forecast_horizon, \n",
    "                        lags_past_covariates=forecast_horizon,\n",
    "                        lags_future_covariates=(int(forecast_horizon/2), 7),\n",
    "                        output_chunk_length=forecast_horizon,\n",
    "                        model=RidgeCV(),\n",
    "                        )\n",
    "\n",
    "\n",
    "# models = [RegressionEnsembleModel(\n",
    "#                                 forecasting_models=[RegressionModel(lags=14, \n",
    "#                                                                     lags_past_covariates=14,\n",
    "#                                                                     lags_future_covariates=(7,2),\n",
    "#                                                                     model=RidgeCV())\n",
    "#                                                    #, LassoCV(), HuberRegressor()\n",
    "#                                                    ], \n",
    "#                                 regression_train_n_points=int(len(scaled_series[0])*0.5*(1-start_split)),\n",
    "#                                 regression_model=ElasticNet()\n",
    "#                 ) \n",
    "#                 for model in range(len(scaled_series))\n",
    "# ]\n",
    "# estimators = [\n",
    "#     ('lr', RidgeCV()),\n",
    "#     ('svr', LassoCV()),\n",
    "#     ('huber', HuberRegressor())\n",
    "# ]\n",
    "\n",
    "# models = [RegressionModel(lags=14, \n",
    "#                           lags_past_covariates=14,\n",
    "#                           lags_future_covariates=(7,2),\n",
    "#                           model=StackingRegressor(\n",
    "#                                               estimators=estimators,\n",
    "#                                               final_estimator=RandomForestRegressor(n_estimators=10)\n",
    "#                             )\n",
    "#                         )\n",
    "#            for model in range(len(scaled_series))\n",
    "# ]\n",
    "\n",
    "local = True\n",
    "\n",
    "if local:\n",
    "    models = full_fit_local_models(models, scaled_series, past_covariates, future_covariates)\n",
    "    print(\"start_backtesting\")\n",
    "    backtests = backtest_local_models(models, scaled_series, past_covariates, \n",
    "                                      future_covariates, forecast_horizon, start_split=start_split, verbose=True)\n",
    "else:\n",
    "    model = fit_global_model(model, splited_series, splited_past_covariates, splited_future_covariates)\n",
    "    backtests = backtest_global_model(model, scaled_series, past_covariates, \n",
    "                                      future_covariates, forecast_horizon, start_split=start_split, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0607f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = calculate_loss(scalers, splited_series, backtests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mmj5OI4qSaPx",
   "metadata": {
    "id": "mmj5OI4qSaPx"
   },
   "outputs": [],
   "source": [
    "plot_backtest_forecasts(scalers, splited_series, backtests)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0eb825c",
   "metadata": {},
   "source": [
    "## Submission "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6Cri58X1iQXw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 244
    },
    "id": "6Cri58X1iQXw",
    "outputId": "e5beb93d-fa97-41c6-bccc-23a1ffb7db38"
   },
   "outputs": [],
   "source": [
    "# init the models \n",
    "from darts.models import RegressionModel\n",
    "from sklearn.linear_model import RidgeCV, TweedieRegressor, ElasticNet, BayesianRidge, LassoCV\n",
    "\n",
    "models = [RegressionModel(lags=28, \n",
    "                          lags_past_covariates=28,\n",
    "                          lags_future_covariates=(7,2),\n",
    "                          model=RidgeCV(),\n",
    "                          output_chunk_length=forecast_horizon\n",
    "                         )\n",
    "          for model in range(len(scaled_series))]\n",
    "models = full_fit_local_models(models, scaled_series, past_covariates, future_covariates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4v7vs9ZaVZvc",
   "metadata": {
    "id": "4v7vs9ZaVZvc"
   },
   "outputs": [],
   "source": [
    "# from datetime import timedelta\n",
    "# predict_past_covariates = [covariate.slice(pd.Timestamp(\"2022-03-07\")-timedelta(days=7), \n",
    "#                                            pd.Timestamp(\"2022-02-06\")) for covariate in past_covariates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kjJmVi6UNfv4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kjJmVi6UNfv4",
    "outputId": "28ff7c6a-fd88-4679-b8ce-519038183205"
   },
   "outputs": [],
   "source": [
    "# from datetime import timedelta\n",
    "# predict_covariates = get_datetime_covariates(pd.Timestamp(\"2022-02-07\")-timedelta(days=7), \n",
    "#                                              pd.Timestamp(\"2022-02-06\")+timedelta(days=forecast_horizon+2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "FSduFMbRe3SX",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FSduFMbRe3SX",
    "outputId": "42748324-6c77-45ea-9681-ebe525112b26"
   },
   "outputs": [],
   "source": [
    "predict_covariates = get_datetime_covariates(pd.Timestamp(\"2022-04-30\"), pd.Timestamp(\"2022-05-27\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2Gpa8f63UTRj",
   "metadata": {
    "id": "2Gpa8f63UTRj"
   },
   "outputs": [],
   "source": [
    "predict_future_covariates = [TimeSeries.from_dataframe(predict_covariates.reset_index(), \n",
    "                                                       time_col='index',\n",
    "                                                       fill_missing_dates=False,\n",
    "                                                       freq='D'\n",
    "                              ) for i in range(100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RWYEOiRSgX2a",
   "metadata": {
    "id": "RWYEOiRSgX2a"
   },
   "outputs": [],
   "source": [
    "from darts import concatenate\n",
    "new_predict_future_covariates = [future_covariates[i].concatenate(predict_future_covariates[i], axis=0) for i in range(len(future_covariates))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Lz7HBVFxNfn2",
   "metadata": {
    "id": "Lz7HBVFxNfn2"
   },
   "outputs": [],
   "source": [
    "forecasts = predict_local_models(models=models,\n",
    "                                 forecast_horizon=forecast_horizon,\n",
    "                                 past_covariates=past_covariates, #predict_past_covariates, \n",
    "                                 future_covariates=new_predict_future_covariates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pCzsoLBkjqJf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "pCzsoLBkjqJf",
    "outputId": "948a43c5-328f-44e9-ac41-5086c51ad6ce"
   },
   "outputs": [],
   "source": [
    "plot_backtest_forecasts(scalers, splited_series, forecasts, slicing=False, scaling=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zdCI1cHIhxh-",
   "metadata": {
    "id": "zdCI1cHIhxh-"
   },
   "outputs": [],
   "source": [
    "scaled_forecast_dfs = [scaled_forecast.pd_dataframe() - 1 for scaled_forecast in inverse_forecasts(scalers, forecasts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Iwl4k80rhxfn",
   "metadata": {
    "id": "Iwl4k80rhxfn"
   },
   "outputs": [],
   "source": [
    "return_forecasts = pd.concat(scaled_forecast_dfs, axis=1)\n",
    "return_forecasts.reset_index().to_csv(\"./results/means_sub3.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d061b545",
   "metadata": {},
   "outputs": [],
   "source": [
    "return_forecasts.iplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bddc2600",
   "metadata": {},
   "outputs": [],
   "source": [
    "backtests = backtest_local_models(models, scaled_series, past_covariates, \n",
    "                                  future_covariates, forecast_horizon, \n",
    "                                  start_split=start_split, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ffbae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_residuals(scalers, forecasts, series, log=False):\n",
    "    residuals = []\n",
    "    for scaler, forecast, serie in list(zip(scalers, forecasts, series)):\n",
    "        forecast = scaler.inverse_transform(forecast)\n",
    "        serie = scaler.inverse_transform(serie)\n",
    "        #print(forecast.values().shape, serie.values().shape)\n",
    "        if log:\n",
    "            forecast = forecast.map(lambda x: (np.exp(x) - 1))\n",
    "            serie = serie.map(lambda x: (np.exp(x) - 1))\n",
    "\n",
    "        residuals.append(\n",
    "            (forecast[-60:] - serie[-60:]).pd_dataframe()\n",
    "        )\n",
    "    return residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a46fc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = get_residuals(scalers, backtests, scaled_series)\n",
    "pd.concat(residuals, axis=1).reset_index().to_csv(\"./results/residuals_sub3.csv\", index=False) #.cov()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9k3OfGonhxdB",
   "metadata": {
    "id": "9k3OfGonhxdB"
   },
   "outputs": [],
   "source": [
    "# scaled_series_dfs = [scaled_serie.pd_dataframe() for scaled_serie in inverse_forecasts(scalers, scaled_series)]\n",
    "# df_serie = pd.concat(scaled_series_dfs, axis=1) #.reset_index() # .to_csv(\"./means.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "HrcJxp1uhxVg",
   "metadata": {
    "id": "HrcJxp1uhxVg"
   },
   "outputs": [],
   "source": [
    "# returns = (df_serie.iloc[-1,:] - pd.concat(scaled_forecast_dfs, axis=1).iloc[-1,:])/pd.concat(scaled_forecast_dfs, axis=1).iloc[-1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3hGX0Jg4zhVf",
   "metadata": {
    "id": "3hGX0Jg4zhVf"
   },
   "outputs": [],
   "source": [
    "return_forecasts.iloc[-1].reset_index().to_csv(\"./results/returns_sub3.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30dadedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "return_forecasts.iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "y6ul2f5U3eTA",
   "metadata": {
    "id": "y6ul2f5U3eTA"
   },
   "outputs": [],
   "source": [
    "cov = pd.concat(residuals, axis=1).cov().values\n",
    "mean = return_forecasts.iloc[-1].values\n",
    "samples = np.random.multivariate_normal(mean, cov, size=100, check_valid='warn', tol=1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "p5tN2zH63eIe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p5tN2zH63eIe",
    "outputId": "9666e517-eb06-4bcc-8cf4-83c8c5e71a87"
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(data=samples).iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hufds3d9zhTH",
   "metadata": {
    "id": "hufds3d9zhTH"
   },
   "outputs": [],
   "source": [
    "group_names = ['strong sell', 'sell', 'hold', 'buy', 'strong buy']\n",
    "\n",
    "out = pd.qcut(pd.DataFrame(data=samples).values.reshape(-1), q=[0, .2, .4, .6, .8, 1.], labels=group_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "huSmr1AwzhQG",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 240
    },
    "id": "huSmr1AwzhQG",
    "outputId": "bd89d756-679e-4a8d-e479-534c7c849101"
   },
   "outputs": [],
   "source": [
    "counts_df = pd.DataFrame(np.array(list(out)).reshape(100,100))\n",
    "counts_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nR3X1Hpt9FnQ",
   "metadata": {
    "id": "nR3X1Hpt9FnQ"
   },
   "outputs": [],
   "source": [
    "counts_df_norm = (counts_df.apply(pd.value_counts)/100).T\n",
    "counts_df_norm = counts_df_norm[['strong sell', 'sell', 'hold', 'buy', 'strong buy']].fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zTR73kzd04iQ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "id": "zTR73kzd04iQ",
    "outputId": "895de895-a9f8-4e94-bbc8-c141970cc1e1"
   },
   "outputs": [],
   "source": [
    "df_submission = pd.read_csv(\"template.csv\", index_col=0)\n",
    "df_submission.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lSZeUd-M04f7",
   "metadata": {
    "id": "lSZeUd-M04f7"
   },
   "outputs": [],
   "source": [
    "df_submission.iloc[:,:-1] = counts_df_norm.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uqgGbLK_04dC",
   "metadata": {
    "id": "uqgGbLK_04dC"
   },
   "outputs": [],
   "source": [
    "df_submission.to_csv(\"./results/submission_sub3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00414f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from metrics import portfolio_rps\n",
    "# df = pd.DataFrame(df_stock_prc_returns.iloc[-4,:]).T\n",
    "# idxs = df.T.round(4).apply(lambda x: (x.rank(ascending=True) // 20 +1).clip(upper=5), axis=0).astype(int)\n",
    "# a = np.zeros((100,5))\n",
    "# np.put_along_axis(a, idxs.values-1, 1, axis=1)\n",
    "# probs = pd.read_csv(\"./results/pilot_submission.csv\", index_col=0).iloc[:,:-1].values\n",
    "# print(portfolio_rps(probs=probs, outcome=a))\n",
    "\n",
    "\n",
    "from metrics import RPS_calculation, IR_calculation\n",
    "#Read asset prices data (as provided by the M6 submission platform)\n",
    "asset_data = pd.read_csv(\"assets_m6.csv\")\n",
    "\n",
    "#Read submission file (similar to the template provided by the M6 submission platform)\n",
    "# submission_data = pd.read_csv(\"template.csv\")\n",
    "submission_data = pd.read_csv(\"./results/pilot_submission.csv\")#, index_col=0)\n",
    "\n",
    "hist_data = asset_data\n",
    "submission = submission_data\n",
    "\n",
    "#Run evaluation\n",
    "RPS_calculation(hist_data = asset_data , submission = submission_data)['RPS']\n",
    "\n",
    "# IR_calculation(hist_data, submission)['IR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97393b6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47dfc3e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181194df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be33c105",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd2cd7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f5aedf",
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "2e4710e9937f4537aba68c5f72193cff",
      "f6910ffddda9448db40a22cf53ccd89b",
      "374964d5127040a3a4351c7aeaa5b6a3",
      "25f212fbbe97430896c9db5358da0198",
      "85b1e6207ea84518b98800ea075dfc08"
     ]
    },
    "id": "72f5aedf",
    "outputId": "6403eff5-230e-4559-f05d-9876daf24c8a"
   },
   "outputs": [],
   "source": [
    "from darts.models import RNNModel\n",
    "from darts.models import TFTModel\n",
    "from darts.models import TCNModel\n",
    "from darts.models import TransformerModel\n",
    "from darts.models import BlockRNNModel\n",
    "\n",
    "from darts.utils.likelihood_models import (\n",
    "    GaussianLikelihood,\n",
    "    PoissonLikelihood,\n",
    "    NegativeBinomialLikelihood,\n",
    "    BernoulliLikelihood,\n",
    "    GammaLikelihood,\n",
    "    GumbelLikelihood,\n",
    "    LaplaceLikelihood,\n",
    "    BetaLikelihood,\n",
    "    ExponentialLikelihood,\n",
    "    DirichletLikelihood,\n",
    "    GeometricLikelihood,\n",
    "    CauchyLikelihood,\n",
    "    ContinuousBernoulliLikelihood,\n",
    "    HalfNormalLikelihood,\n",
    "    LogNormalLikelihood,\n",
    "    WeibullLikelihood,\n",
    "    QuantileRegression,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "brnn_no_cov = BlockRNNModel(input_chunk_length=input_chunk_length,\n",
    "                            output_chunk_length=forecast_horizon,\n",
    "                            n_rnn_layers=2,\n",
    "                            likelihood=QuantileRegression(quantiles=quantiles),\n",
    "                            random_state=42)\n",
    "\n",
    "deepar = RNNModel(input_chunk_length=38, \n",
    "                  output_chunk_length=19, \n",
    "                  n_rnn_layers=2, \n",
    "                  model=\"LSTM\",\n",
    "                  #hidden_dim=20,\n",
    "                  dropout=0.1,\n",
    "                  batch_size=256,\n",
    "                  n_epochs=10,\n",
    "                  optimizer_kwargs={\"lr\": 1e-3},\n",
    "                  random_state=0,\n",
    "                  likelihood=BetaLikelihood()#QuantileRegression(quantiles=quantiles),\n",
    "                 )\n",
    "\n",
    "deepar = TFTModel(\n",
    "        input_chunk_length=input_chunk_length,\n",
    "        output_chunk_length=forecast_horizon,\n",
    "        hidden_size=64,\n",
    "        lstm_layers=1,\n",
    "        num_attention_heads=4,\n",
    "        dropout=0.1,\n",
    "        batch_size=256,\n",
    "        n_epochs=10,\n",
    "        add_relative_index=False,\n",
    "        add_encoders=None,\n",
    "        likelihood=QuantileRegression(\n",
    "            quantiles=quantiles\n",
    "        ),  # QuantileRegression is set per default\n",
    "        # loss_fn=MSELoss(),\n",
    "        random_state=42,\n",
    ")\n",
    "\n",
    "deeptcn = TCNModel(\n",
    "    input_chunk_length=input_chunk_length,\n",
    "    output_chunk_length=forecast_horizon,\n",
    "    batch_size=256,\n",
    "    kernel_size=2,\n",
    "    num_filters=4,\n",
    "    dilation_base=2,\n",
    "    dropout=0.1,\n",
    "    random_state=0,\n",
    "    likelihood=QuantileRegression(\n",
    "            quantiles=quantiles\n",
    "        )\n",
    ")\n",
    "\n",
    "trans_model = TransformerModel(\n",
    "    input_chunk_length=input_chunk_length,\n",
    "    output_chunk_length=forecast_horizon,\n",
    "    batch_size=256,\n",
    "    n_epochs=10,\n",
    "    model_name=\"transformer\",\n",
    "    nr_epochs_val_period=1,\n",
    "    d_model=16,\n",
    "    nhead=8,\n",
    "    num_encoder_layers=2,\n",
    "    num_decoder_layers=2,\n",
    "    dim_feedforward=128,\n",
    "    dropout=0.1,\n",
    "    activation=\"relu\",\n",
    "    random_state=42,\n",
    "    save_checkpoints=True,\n",
    "    force_reset=True,\n",
    ")\n",
    "\n",
    "\n",
    "from darts.models import NBEATSModel\n",
    "\n",
    "encoders = {\n",
    "    \"cyclic\": {\"future\": [\"month\",\"day\"]},\n",
    "    \"datetime_attribute\": {\"future\": [\"dayofweek\", \"day\"]},\n",
    "    \"position\": {\"future\": [\"relative\"]},\n",
    "    #\"position\": {\"past\": [\"absolute\"], \"future\": [\"relative\"]},\n",
    "    #\"custom\": {\"past\": [lambda idx: (idx.day - 1950) / 50]},\n",
    "    \"transformer\": Scaler(),\n",
    "}\n",
    "\n",
    "\n",
    "model_nbeats = NBEATSModel(\n",
    "    input_chunk_length=input_chunk_length,\n",
    "    output_chunk_length=forecast_horizon,\n",
    "    generic_architecture=True,\n",
    "    num_stacks=10,\n",
    "    num_blocks=1,\n",
    "    num_layers=4,\n",
    "    layer_widths=512,\n",
    "    n_epochs=10,\n",
    "    nr_epochs_val_period=1,\n",
    "    batch_size=256,\n",
    "    model_name=\"nbeats_run\",\n",
    "    likelihood=QuantileRegression(quantiles=quantiles),\n",
    ")\n",
    "\n",
    "for serie, past_cov, future_cov in list(zip(splited_series, \n",
    "                                            splited_past_covariates, \n",
    "                                            splited_future_covariates)):\n",
    "    model_nbeats.fit(series=serie[0], \n",
    "                     past_covariates=past_cov[0],\n",
    "                     val_series=serie[1].drop_after(0.5),\n",
    "                     val_past_covariates=past_cov[1].drop_after(0.5),\n",
    "                     verbose=True)\n",
    "\n",
    "for serie, past_cov, future_cov in list(zip(splited_series, \n",
    "                                            splited_past_covariates, \n",
    "                                            splited_future_covariates)):\n",
    "    deepar.fit(series=serie[0], \n",
    "               #past_covariates=past_cov[0],\n",
    "               future_covariates=future_cov[0],\n",
    "               val_series=serie[1].drop_after(0.5),\n",
    "               #val_past_covariates=past_cov[1].drop_after(0.5),\n",
    "               val_future_covariates=future_cov[1].drop_after(0.5),\n",
    "               verbose=True,\n",
    "               #epochs=10\n",
    "              )\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9a0317",
   "metadata": {
    "id": "0d9a0317"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee31275",
   "metadata": {
    "id": "cee31275"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3451964",
   "metadata": {
    "id": "a3451964"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dc63743e",
   "metadata": {
    "id": "dc63743e"
   },
   "source": [
    "### Naive models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566c268c",
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "2abb72517b9346908966b63a3492583d",
      "e98eb88523a640469bfd27492b139ebf",
      "ded66d7cda4145aa801f44e8485f32f9",
      "378a24422e8148ea8a4bbde636b56a9a",
      "67a32819b0ad41da944f7153b9340406"
     ]
    },
    "id": "566c268c",
    "outputId": "c866213e-8243-431a-df25-c0e93bc56097"
   },
   "outputs": [],
   "source": [
    "from darts.models import NaiveEnsembleModel\n",
    "from darts.models import NaiveSeasonal\n",
    "from darts.models import NaiveDrift\n",
    "from sklearn.linear_model import RidgeCV, TweedieRegressor, ElasticNet, BayesianRidge, LassoCV\n",
    "# TweedieRegressor(power=2, alphas = np.logspace(-6, 6, 25))\n",
    "from darts.models.forecasting.linear_regression_model import LinearRegressionModel\n",
    "\n",
    "\n",
    "naive_models = [RegressionEnsembleModel(\n",
    "                                forecasting_models=[NaiveDrift(), NaiveSeasonal(14), NaiveSeasonal(7)], \n",
    "                                regression_train_n_points=int(len(scaled_series[0])*0.5*(1-start_split)),\n",
    "                                regression_model=ElasticNet()\n",
    "                ) \n",
    "                for model in range(len(scaled_series))\n",
    "]\n",
    "\n",
    "for model, serie, past_cov, future_cov in list(zip(naive_models, \n",
    "                                                   splited_series, \n",
    "                                                   splited_past_covariates, \n",
    "                                                   splited_future_covariates)):\n",
    "    model.fit(series=serie[0], \n",
    "              #past_covariates=past_cov[0],\n",
    "              future_covariates=future_cov[0],\n",
    "              #verbose=True\n",
    "         )\n",
    "\n",
    "backtests = [model.historical_forecasts(series=serie,\n",
    "                                        start=start_split+0.5*(1-start_split),\n",
    "                                        #past_covariates=past_cov,\n",
    "                                        future_covariates=future_cov,\n",
    "                                        forecast_horizon=forecast_horizon,\n",
    "                                        stride=1,\n",
    "                                        retrain=True,\n",
    "                                        last_points_only=True,\n",
    "                                        verbose=True)\n",
    "             \n",
    "             for model, serie, past_cov, future_cov in list(zip(naive_models, \n",
    "                                                                scaled_series, \n",
    "                                                                past_covariates, \n",
    "                                                                future_covariates))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3481b3bd",
   "metadata": {
    "id": "3481b3bd",
    "outputId": "e0acf8ee-8b60-45ff-d1e2-1b93220268b1"
   },
   "outputs": [],
   "source": [
    "from utils import print_error_metrics\n",
    "\n",
    "calculate_loss(scalers, splited_series, backtests)\n",
    "\n",
    "for scaler, serie_list, backtest, covs in list(zip(scalers, splited_series, backtests, past_covariates)):\n",
    "    val_serie = serie_list[1]\n",
    "    \n",
    "    val_serie = scaler.inverse_transform(val_serie)\n",
    "    backtest = scaler.inverse_transform(backtest)\n",
    "    \n",
    "    val_serie = val_serie.map(lambda x: (np.exp(x) - 1))\n",
    "    backtest = backtest.map(lambda x: (np.exp(x) - 1))\n",
    "    \n",
    "    slice_size = 1000\n",
    "    val_serie.slice_intersect(backtest)[:slice_size].plot(label='data')\n",
    "    backtest[:slice_size].plot(lw=2, label='forecast')\n",
    "    #covs.slice_intersect(backtest)[:slice_size].plot(label='covariates')\n",
    "    error = print_error_metrics(val_serie.slice_intersect(backtest).values(), backtest.values())\n",
    "    \n",
    "    plt.title(f'MAPE: {mape(val_serie,backtest)}, RMSE: {rmse(val_serie, backtest)}')\n",
    "    plt.title(error)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "# print(\n",
    "#     f\"Mean Absolute Error:     {mae.mean():.3f} +/- {mae.std():.3f}\\n\"\n",
    "#     f\"Root Mean Squared Error: {rmse.mean():.3f} +/- {rmse.std():.3f}\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3c85a2",
   "metadata": {
    "id": "9f3c85a2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1975cd3c",
   "metadata": {
    "id": "1975cd3c"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be68d2d6",
   "metadata": {
    "id": "be68d2d6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462e8246",
   "metadata": {
    "id": "462e8246"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15761c5",
   "metadata": {
    "id": "e15761c5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91de84f",
   "metadata": {
    "id": "e91de84f"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37bc3abb",
   "metadata": {
    "id": "37bc3abb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5164b28a",
   "metadata": {
    "id": "5164b28a"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706864c9",
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "088524444fa542cd976d29d2c8280aca",
      "f531ce965768487da529a2438c58c065"
     ]
    },
    "id": "706864c9",
    "outputId": "fba9607f-2ead-4479-eb32-580078c60703"
   },
   "outputs": [],
   "source": [
    "# backtest the models \n",
    "from darts.utils.statistics import plot_hist\n",
    "\n",
    "for serie, past_cov, future_cov in list(zip(scaled_series, past_covariates, future_covs)):\n",
    "    raw_errors = model.backtest(\n",
    "        series=serie,\n",
    "        past_covariates=past_cov,\n",
    "        future_covariates=future_cov,\n",
    "        start=start_split,\n",
    "        forecast_horizon=forecast_horizon,\n",
    "        stride=1,\n",
    "        retrain=False,\n",
    "        last_points_only=True,\n",
    "        #metric=mape, \n",
    "        reduction=None, \n",
    "        verbose=True,\n",
    "    )\n",
    "\n",
    "    plot_hist(\n",
    "        raw_errors,\n",
    "        bins=np.arange(0, max(raw_errors), 1),\n",
    "        title=\"Individual backtest error scores (histogram)\",\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a1ca48",
   "metadata": {
    "id": "59a1ca48"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6adc89eb",
   "metadata": {
    "id": "6adc89eb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a80f433",
   "metadata": {
    "id": "9a80f433"
   },
   "outputs": [],
   "source": [
    "def eval_model(model):\n",
    "    model.fit(train)\n",
    "    forecast = model.predict(len(val))\n",
    "    print(\"model {} obtains MAPE: {:.2f}%\".format(model, mape(val, forecast)))\n",
    "    \n",
    "from darts.utils.statistics import plot_residuals_analysis, plot_hist, display_forecast\n",
    "pred_series = model_nbeats.historical_forecasts(\n",
    "    series,\n",
    "    start=pd.Timestamp(\"20170901\"),\n",
    "    forecast_horizon=7,\n",
    "    stride=5,\n",
    "    retrain=False,\n",
    "    verbose=True,\n",
    ")\n",
    "display_forecast(pred_series, series, \"7 day\", start_date=pd.Timestamp(\"20170901\"))\n",
    "\n",
    "\n",
    "plot_residuals_analysis(best_theta_model.residuals(series))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79945e88",
   "metadata": {
    "id": "79945e88"
   },
   "outputs": [],
   "source": [
    "raw_errors = best_theta_model.backtest(\n",
    "    series, start=0.6, forecast_horizon=3, metric=mape, reduction=None, verbose=True\n",
    ")\n",
    "\n",
    "from darts.utils.statistics import plot_hist\n",
    "\n",
    "plot_hist(\n",
    "    raw_errors,\n",
    "    bins=np.arange(0, max(raw_errors), 1),\n",
    "    title=\"Individual backtest error scores (histogram)\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24dde252",
   "metadata": {
    "id": "24dde252"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f568b8",
   "metadata": {
    "id": "f1f568b8"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "dc63743e"
   ],
   "name": "Darts forecasts.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('datascience')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "c8e0bb0da2aff65736b499a73199d9b3916fe5784b22bc0d777fb56d771df7b1"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "073685966c774b01953c0343bef00251": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "08db2b9a48c542adbe8cc7e06bb31871": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c6d702c50e9840e69a9e75caf2bdb4b0",
      "max": 100,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4d8362c0442e446abcd1f36928c2b8e9",
      "value": 100
     }
    },
    "1add1e8945964e189c63557224b740fc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4c3eb9334739464aaa3ef7b87c6369ac",
      "max": 100,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c0774078b6954b58afa08a657c648e37",
      "value": 100
     }
    },
    "3fb3e0fe97e54db99c0532a66911bc84": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_073685966c774b01953c0343bef00251",
      "placeholder": "​",
      "style": "IPY_MODEL_f3fc925008d64eb3af346326f11737cf",
      "value": "100%"
     }
    },
    "4c2e235e63d64196964deec526f3784c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4c3eb9334739464aaa3ef7b87c6369ac": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4d8362c0442e446abcd1f36928c2b8e9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "53173af3160b4b758ed2c33d3b554008": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_75bdf511cc3242eaae63569a7d40f4b6",
      "placeholder": "​",
      "style": "IPY_MODEL_e6f3d7eb344d40a4b9fd97a3617a94f9",
      "value": " 100/100 [00:05&lt;00:00, 20.52it/s]"
     }
    },
    "5b705b8c225d4d76b46b50c9f510a40e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c575ac2e09424c3f8fc76c924b1314f4",
       "IPY_MODEL_08db2b9a48c542adbe8cc7e06bb31871",
       "IPY_MODEL_53173af3160b4b758ed2c33d3b554008"
      ],
      "layout": "IPY_MODEL_86f69349b4b94dc68923fbcd72d1a2b1"
     }
    },
    "742a3ef153ee4c1fa4a7ced4c899c0e0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "75bdf511cc3242eaae63569a7d40f4b6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "81ff9d16b3624054984a94baf2998fad": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "86f69349b4b94dc68923fbcd72d1a2b1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "96bdac24271c490caeafed06be53e2fd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_742a3ef153ee4c1fa4a7ced4c899c0e0",
      "placeholder": "​",
      "style": "IPY_MODEL_ec425fa026f84d359130572ee193b14f",
      "value": " 100/100 [00:24&lt;00:00,  4.91it/s]"
     }
    },
    "b7d303b547924163acb02c690cfac7c7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3fb3e0fe97e54db99c0532a66911bc84",
       "IPY_MODEL_1add1e8945964e189c63557224b740fc",
       "IPY_MODEL_96bdac24271c490caeafed06be53e2fd"
      ],
      "layout": "IPY_MODEL_81ff9d16b3624054984a94baf2998fad"
     }
    },
    "bb65e7a00bbb44c6aa1ec72f33b64221": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c0774078b6954b58afa08a657c648e37": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c575ac2e09424c3f8fc76c924b1314f4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4c2e235e63d64196964deec526f3784c",
      "placeholder": "​",
      "style": "IPY_MODEL_bb65e7a00bbb44c6aa1ec72f33b64221",
      "value": "100%"
     }
    },
    "c6d702c50e9840e69a9e75caf2bdb4b0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e6f3d7eb344d40a4b9fd97a3617a94f9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ec425fa026f84d359130572ee193b14f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f3fc925008d64eb3af346326f11737cf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
