{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b578512d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. magic for inline plot\n",
    "# 2. magic to print version\n",
    "# 3. magic so that the notebook will reload external python modules\n",
    "# 4. magic to enable retina (high resolution) plots\n",
    "# https://gist.github.com/minrk/3301035\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext watermark\n",
    "%autoreload 2\n",
    "%config InlineBackend.figure_format='retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad15aa6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345133f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import plotly\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4dcda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.offline\n",
    "import cufflinks as cf\n",
    "cf.go_offline()\n",
    "cf.set_config_file(offline=False, world_readable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c297f44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda install darts\n",
    "import darts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b284c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "data_path = Path.cwd().parent / \"data\" \n",
    "df_m6 = pd.read_csv(data_path / \"template/M6_Universe.csv\", index_col=0)\n",
    "df_m6.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea5853c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from datetime import datetime\n",
    "from src.utils import get_ticker_historical_data\n",
    "import os\n",
    "\n",
    "directory = './tickers'\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "tickers = df_m6[\"symbol\"].to_list()\n",
    "tickers_data = dict()\n",
    "from_date = pd.to_datetime(\"2000-01-01\")\n",
    "\n",
    "to_date = pd.Timestamp.today()\n",
    "to_date.tz_localize(tz='Europe/Moscow').tz_convert(tz='America/New_York')\n",
    "to_date.replace(hour=0, minute=0, second=0, microsecond=0)\n",
    "\n",
    "# to_date = pd.to_datetime(\"2022-01-30\")\n",
    "interval = '1d'\n",
    "\n",
    "for ticker in tqdm(tickers[:]): \n",
    "    #print(f\"Ticker: {ticker}\")\n",
    "    data = get_ticker_historical_data(ticker=ticker,\n",
    "                                      from_date=from_date,\n",
    "                                      to_date=to_date,\n",
    "                                      interval=interval\n",
    "                                      )\n",
    "    tickers_data[ticker] = data\n",
    "    data.reset_index().to_csv(os.path.join(directory,f'{ticker}_{interval}.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1330efbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = tickers_data['AVB'].copy()\n",
    "# add moving averages to df\n",
    "df['MA20'] = df['Adj Close'].rolling(window=20).mean()\n",
    "df['MA50'] = df['Adj Close'].rolling(window=50).mean()\n",
    "df.dropna(inplace=True, axis=0)\n",
    "\n",
    "# !pip install ta -q \n",
    "from ta.trend import MACD\n",
    "# MACD\n",
    "macd = MACD(close=df['Adj Close'], \n",
    "            window_slow=50,\n",
    "            window_fast=20, \n",
    "            window_sign=20)\n",
    "\n",
    "df = df.iloc[-500:,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc53ea9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on https://python.plainenglish.io/a-simple-guide-to-plotly-for-plotting-financial-chart-54986c996682\n",
    "fig = make_subplots(rows=3, cols=1, shared_xaxes=True,\n",
    "                    vertical_spacing=0.01, \n",
    "                    row_heights=[0.5,0.2,0.2])\n",
    "\n",
    "#fig = go.Figure()\n",
    "fig = make_subplots(rows=3, cols=1, shared_xaxes=True)\n",
    "\n",
    "# add OHLC trace\n",
    "fig.add_trace(go.Candlestick(x=df.index,\n",
    "                             open=df['Open'],\n",
    "                             high=df['High'],\n",
    "                             low=df['Low'],\n",
    "                             close=df['Close'], \n",
    "                             showlegend=False))\n",
    "\n",
    "fig.add_trace(go.Scatter(x=df.index, \n",
    "                         y=df['MA50'], \n",
    "                         opacity=0.7, \n",
    "                         line=dict(color='blue', width=2), \n",
    "                         name='MA 50'))\n",
    "fig.add_trace(go.Scatter(x=df.index, \n",
    "                         y=df['MA20'], \n",
    "                         opacity=0.7, \n",
    "                         line=dict(color='orange', width=2), \n",
    "                         name='MA 20'))\n",
    "\n",
    "\n",
    "\n",
    "# Plot volume trace on 2nd row\n",
    "colors = ['green' if row['Open'] - row['Close'] >= 0 \n",
    "          else 'red' for index, row in df.iterrows()]\n",
    "fig.add_trace(go.Bar(x=df.index, \n",
    "                     y=df['Volume'],\n",
    "                     marker_color=colors\n",
    "                    ), row=2, col=1)\n",
    "\n",
    "\n",
    "# Plot MACD trace on 3rd row\n",
    "colors = ['green' if val >= 0 \n",
    "          else 'red' for val in macd.macd_diff()]\n",
    "fig.add_trace(go.Bar(x=df.index, \n",
    "                     y=macd.macd_diff(),\n",
    "                     marker_color=colors,\n",
    "                     opacity=0.7,\n",
    "                    ), row=3, col=1)\n",
    "\n",
    "fig.add_trace(go.Scatter(x=df.index,\n",
    "                         y=macd.macd(),\n",
    "                         line=dict(color='black', width=2)\n",
    "                        ), row=3, col=1)\n",
    "\n",
    "fig.add_trace(go.Scatter(x=df.index,\n",
    "                         y=macd.macd_signal(),\n",
    "                         line=dict(color='blue', width=1)\n",
    "                        ), row=3, col=1)\n",
    "\n",
    "\n",
    "\n",
    "# remove rangeslider\n",
    "fig.update_layout(xaxis_rangeslider_visible=False)\n",
    "\n",
    "# add chart title \n",
    "fig.update_layout(title=\"AAPL\")\n",
    "\n",
    "# fig.update_layout(\n",
    "#     title=\"Plot Title\",\n",
    "#     xaxis_title=\"X Axis Title\",\n",
    "#     yaxis_title=\"Y Axis Title\",\n",
    "#     legend_title=\"Legend Title\",\n",
    "#     font=dict(\n",
    "#         family=\"Courier New, monospace\",\n",
    "#         size=18,\n",
    "#         color=\"RebeccaPurple\"\n",
    "#     )\n",
    "# )\n",
    "\n",
    "\n",
    "# removing all empty dates\n",
    "# build complete timeline from start date to end date\n",
    "dt_all = pd.date_range(start=df.index[0],end=df.index[-1])\n",
    "# retrieve the dates that ARE in the original datset\n",
    "dt_obs = [d.strftime(\"%Y-%m-%d\") for d in pd.to_datetime(df.index)]\n",
    "# define dates with missing values\n",
    "dt_breaks = [d for d in dt_all.strftime(\"%Y-%m-%d\").tolist() if not d in dt_obs]\n",
    "fig.update_xaxes(rangebreaks=[dict(values=dt_breaks)])\n",
    "\n",
    "# removing white space\n",
    "fig.update_layout(margin=go.layout.Margin(\n",
    "        l=40, #left margin\n",
    "        r=40, #right margin\n",
    "        b=40, #bottom margin\n",
    "        t=40  #top margin\n",
    "    ))\n",
    "\n",
    "# update y-axis label\n",
    "fig.update_yaxes(title_text=\"Price\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"Volume\", row=2, col=1)\n",
    "fig.update_yaxes(title_text=\"MACD\", showgrid=False, row=3, col=1)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94062af",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = tickers_data['AEP'].copy()\n",
    "# if 'Close' in df.columns:\n",
    "#     df.drop('Close', axis=1, inplace=True)\n",
    "# # df.columns = [x.lower() for x in df.columns]\n",
    "# df['Pct_change'] = df['Adj Close'].pct_change()\n",
    "# df['Cumsum_Pct_change'] = (df['Pct_change']).cumprod()\n",
    "# df['Realized_volatility'] = df['Pct_change'].rolling(3).std()\n",
    "# # df_month = df.copy()\n",
    "\n",
    "# df_month = df_month.resample('M').agg({'Open': np.mean,\n",
    "#                                        'High': np.mean, \n",
    "#                                        'Close': np.mean,\n",
    "#                                        'Adj Close': np.mean,\n",
    "#                                        'Volume':np.mean\n",
    "#                                        })\n",
    "# df_month['monthly_returns'] = df_month['Adj Close'].pct_change()\n",
    "# df_month\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c513e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas_ta as ta\n",
    "# df.ta.indicators()\n",
    "# df.ta.log_return(cumulative=True, append=True)\n",
    "# df.ta.percent_return(cumulative=True, append=True)\n",
    "# df.ta.sma(length=50, append=True)\n",
    "# df.ta.sma(length=?20, append=True)\n",
    "# df.ta.strategy(\"Momentum\") \n",
    "# df.ta.strategy(fast=10, slow=50, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07afacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import plotly.express as px\n",
    "\n",
    "# fig = px.line(df, x=df.index, y=\"cumsum_pct_change\", \n",
    "#               title='Cumulative returns', #text='Date'\n",
    "#              )\n",
    "# fig.update_traces(textposition=\"bottom right\")\n",
    "# fig.show()\n",
    "# df['Pct_change'] = df['Adj Close'].pct_change()\n",
    "# df['Cumsum_Pct_change'] = (df['Pct_change']).cumprod()\n",
    "# df['Realized_volatility'] = df['Pct_change'].rolling(3).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3622e375",
   "metadata": {},
   "outputs": [],
   "source": [
    "from strategy import SMAStrategy, EMAStrategy, TestStrategy\n",
    "\n",
    "sma = TestStrategy(strategy=SMAStrategy(),\n",
    "                   short_window=50, \n",
    "                   long_window=200,\n",
    "                   close_name='Adj Close',\n",
    "                   )\n",
    "\n",
    "df = tickers_data['AVB'].copy()\n",
    "df = sma.run(data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58d949f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b4cda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the cumulative daily returns in percentage \n",
    "df['cum_return_pct']=(((1 + df['Adj Close'].pct_change(periods=1)).cumprod() - 1))*100\n",
    "\n",
    "fig = px.line(df, x=df.index,\n",
    "              y='cum_return_pct', #color='ticker',\n",
    "              title='Performance - Daily Cumulative Returns',\n",
    "              labels={'cum_return_pct':'daily cumulative returns (%)', })\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01df8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ma_return'].iplot(kind=\"hist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20224595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the cumulative daily returns in percentage \n",
    "df['cum_logg_return_pct']=np.exp((np.log(1 + df['Adj Close'].pct_change(periods=1))).cumsum())-1\n",
    "\n",
    "fig = px.line(df, x=df.index,\n",
    "              y='cum_logg_return_pct', #color='ticker',\n",
    "              title='Performance - Daily Cumulative Returns',\n",
    "              labels={'cum_return_pct':'daily cumulative returns (%)', })\n",
    "fig.show()\n",
    "\n",
    "# log_ret = np.log(1+simple_ret)\n",
    "#     np.exp(log_ret.cumsum()[-1]) -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19f665a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cum_return_pct_roll']=(((1 + df['Adj Close'].rolling(1).mean().pct_change(periods=1)).cumprod() - 1))*100\n",
    "df[['cum_return_pct_roll','cum_return_pct']].iplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5c080c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from reduce_memory import ReduceMemoryTransformer\n",
    "from nyse_holidays import NYSECalendar\n",
    "\n",
    "# Pipeline: \n",
    "\"\"\"\n",
    "A. Make regression for 50 tickets (stocks + ETF groups) for 19 days\n",
    "    - global DL model on all series and datetime covariates \n",
    "    - emsemble model per series with finatial and datetime covariates \n",
    "    - standalone lightgbm model per series with finacial and datetime covariates \n",
    "    - hyperparameter optimization\n",
    "B. Make covariance matrix from the forecast residuals\n",
    "C. Create random forecast variable and sample 100 times\n",
    "D. Optimize portfolio to minimize risks \n",
    "E. Train model on residuals \n",
    "\n",
    "\"\"\" \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db1946d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b484f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "probs = np.array([[0.0, 0.2, 0.3, 0.4, 0.1], \n",
    "                  [0.0, 0.2, 0.3, 0.4, 0.1],\n",
    "                  [0.0, 0.2, 0.3, 0.4, 0.1]]\n",
    "                )\n",
    "outco = np.array([[0, 0, 0, 1, 0], \n",
    "                  [0, 0, 0, 1, 0],\n",
    "                  [0, 0, 0, 1, 0]]\n",
    "                )\n",
    "portfolio_rps(probs, outco)\n",
    "\n",
    "rps(probs=np.array([0.0, 0.2, 0.3, 0.4, 0.1]),\n",
    "    outcome=np.array([0, 0, 0, 1, 0]))\n",
    "\n",
    "from sklearn.metrics import make_scorer\n",
    "rps_score = make_scorer(rps, greater_is_better=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac681c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins=[-300, -11, -5, 5, 11, 300]\n",
    "group_names = ['strong sell', 'sell', 'hold', 'buy', 'strong buy']\n",
    "stocks['short_result'] = pd.cut(stocks['short_result'], bins=bins, labels=group_names, ordered=False)\n",
    "stocks['short_result'].unique()\n",
    "pd.qcut(range(5), q=[0, .25, .5, .75, 1.], labels=group_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf61897",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c0bbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_building(df_data, asset_id):\n",
    "    print(f\"Building asset {asset_id}\")\n",
    "    data_set = df_data[df_data['Asset_ID'] == asset_id]\n",
    "    df = get_features(data_set)\n",
    "    df = df.replace([np.inf, -np.inf], np.nan).dropna(how=\"any\")\n",
    "    \n",
    "    df = reduce_memory_usage(df)\n",
    "    \n",
    "    X = df.drop(['Target'], axis=1)\n",
    "    y = df[\"Target\"]\n",
    "    \n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.25, random_state=24, shuffle=False)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_valid = scaler.transform(X_valid)\n",
    "    \n",
    "    model = LGBMRegressor(\n",
    "        n_estimators=1500, \n",
    "        num_leaves=700,\n",
    "        objective=\"regression\",\n",
    "        metric=\"rmse\",\n",
    "        boosting_type=\"gbdt\",\n",
    "        learning_rate=0.01,\n",
    "        random_state=24,\n",
    "        verbose=0,\n",
    "        force_col_wise=True,\n",
    "    )\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "        \n",
    "    return X_train, y_train, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fe9b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "Xs = {}\n",
    "ys = {}\n",
    "models = {}\n",
    "print('Training Starting...')\n",
    "\n",
    "for asset, asset_name in zip(asset_id[\"Asset_ID\"], asset_id[\"Asset_Name\"]):\n",
    "    X, y, model = model_building(data, asset)\n",
    "    Xs[asset], ys[asset], models[asset] = X, y, model\n",
    "print('Training Completed !!!')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.9 (datascience)",
   "language": "python",
   "name": "datascience"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
